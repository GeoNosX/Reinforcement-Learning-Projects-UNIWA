{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4DWkFe5nd1CH",
        "ciwDpaHtdlfQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install tensorboardX\n",
        "!pip -q install ale-py\n",
        "!pip -q install \"gymnasium[atari,accept-rom-license,other]\" ale-py\n"
      ],
      "metadata": {
        "id": "UZrXMdcFhk9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccf8ede-26e3-4b84-8ea7-de66e0f98fba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Some Wrappers\n",
        "___"
      ],
      "metadata": {
        "id": "4DWkFe5nd1CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "\n",
        "# ========================\n",
        "# FireResetEnv\n",
        "# ========================\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(FireResetEnv, self).__init__(env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "\n",
        "        # Gymnasium step returns 5 values\n",
        "        obs, _, terminated, truncated, info = self.env.step(1)\n",
        "        if terminated or truncated:\n",
        "            obs, info = self.env.reset()\n",
        "\n",
        "        obs, _, terminated, truncated, info = self.env.step(2)\n",
        "        if terminated or truncated:\n",
        "            obs, info = self.env.reset()\n",
        "\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)\n",
        "\n",
        "\n",
        "# ========================\n",
        "# MaxAndSkipEnv\n",
        "# ========================\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        info = {}\n",
        "\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        self._obs_buffer.clear()\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs, info\n",
        "\n",
        "\n",
        "# ========================\n",
        "# ProcessFrame84\n",
        "# ========================\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255, shape=(84, 84, 1), dtype=np.uint8\n",
        "        )\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = frame.reshape(210, 160, 3).astype(np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = frame.reshape(250, 160, 3).astype(np.float32)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown resolution.\")\n",
        "\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = x_t.reshape(84, 84, 1)\n",
        "\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "# ========================\n",
        "# ImageToPyTorch\n",
        "# ========================\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(old_shape[-1], old_shape[0], old_shape[1]),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "# ========================\n",
        "# ScaledFloatFrame\n",
        "# ========================\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "# ========================\n",
        "# BufferWrapper\n",
        "# ========================\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=np.repeat(old_space.low, n_steps, axis=0),\n",
        "            high=np.repeat(old_space.high, n_steps, axis=0),\n",
        "            dtype=dtype,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "        self.buffer = np.zeros_like(self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(obs), info\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "# ========================\n",
        "# make_env\n",
        "# ========================\n",
        "def make_env(env_name):\n",
        "    env = gym.make(env_name, render_mode=None)\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    env = ScaledFloatFrame(env)\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "DubxpLAmdzbJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The DQN\n",
        "___"
      ],
      "metadata": {
        "id": "ciwDpaHtdlfQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jlabo4SKdc0s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        return self.fc(conv_out)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_UKsUnMeHhk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Agent And Training Loop\n",
        "___"
      ],
      "metadata": {
        "id": "mGG28BmxeIZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "DEFAULT_ENV_NAME = \"ALE/SpaceInvaders-v5\"\n",
        "MEAN_REWARD_BOUND = 500\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "REPLAY_START_SIZE = 10000\n",
        "\n",
        "EPSILON_DECAY_LAST_FRAME = 10**5\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.02\n",
        "\n",
        "\n",
        "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n",
        "\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
        "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
        "               np.array(dones, dtype=np.uint8), np.array(next_states)\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env, exp_buffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        # env.reset() in gymnasium returns (observation, info), so we unpack them.\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
        "        done_reward = None\n",
        "\n",
        "        if np.random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_a = np.asarray([self.state])\n",
        "            state_v = torch.tensor(state_a).to(device)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        # do step in the environment\n",
        "        # env.step() in gymnasium returns (observation, reward, terminated, truncated, info)\n",
        "        new_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "        is_done = terminated or truncated # Combine terminated and truncated for 'done'\n",
        "        self.total_reward += reward\n",
        "\n",
        "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
        "        self.exp_buffer.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward\n",
        "\n",
        "\n",
        "def calc_loss(batch, net, tgt_net, device):\n",
        "    states, actions, rewards, dones, next_states = batch\n",
        "\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "\n",
        "    # ✔ Create boolean mask FROM dones array\n",
        "    done_mask = torch.as_tensor(dones, dtype=torch.bool, device=device)\n",
        "\n",
        "    # Q(s, a)\n",
        "    state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    # max_a' Q'(s', a')\n",
        "    next_state_values = tgt_net(next_states_v).max(1)[0]\n",
        "\n",
        "    # ✔ Zero out next_state_values where done=True\n",
        "    next_state_values = next_state_values.masked_fill(done_mask, 0.0)\n",
        "    next_state_values = next_state_values.detach()\n",
        "\n",
        "    expected_state_action_values = rewards_v + GAMMA * next_state_values\n",
        "\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cuda\", default=False, action=\"store_true\", help=\"Enable cuda\")\n",
        "    parser.add_argument(\"--env\", default=DEFAULT_ENV_NAME,\n",
        "                        help=\"Name of the environment, default=\" + DEFAULT_ENV_NAME)\n",
        "    parser.add_argument(\"--reward\", type=float, default=MEAN_REWARD_BOUND,\n",
        "                        help=\"Mean reward boundary for stop of training, default=%.2f\" % MEAN_REWARD_BOUND)\n",
        "    args = parser.parse_args([]) # Pass an empty list for argparse to avoid system exit\n",
        "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "    env = make_env(args.env) # Changed to use the global make_env\n",
        "\n",
        "    net = DQN(env.observation_space.shape, env.action_space.n).to(device) # Changed to use global DQN\n",
        "    tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device) # Changed to use global DQN\n",
        "    writer = SummaryWriter(comment=\"-\" + args.env)\n",
        "    print(net)\n",
        "\n",
        "    buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "    agent = Agent(env, buffer)\n",
        "    epsilon = EPSILON_START\n",
        "\n",
        "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "    total_rewards = []\n",
        "    frame_idx = 0\n",
        "    ts_frame = 0\n",
        "    ts = time.time()\n",
        "    best_mean_reward = None\n",
        "\n",
        "    mean_rewards_filepath = args.env.replace(\"/\", \"_\") + \"_mean_rewards.csv\"\n",
        "\n",
        "\n",
        "    while True:\n",
        "        frame_idx += 1\n",
        "        epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "        reward = agent.play_step(net, epsilon, device=device)\n",
        "        if reward is not None:\n",
        "            total_rewards.append(reward)\n",
        "            num_games = len(total_rewards)\n",
        "            speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "            ts_frame = frame_idx\n",
        "            ts = time.time()\n",
        "            mean_reward = np.mean(total_rewards[-100:])\n",
        "            print(f\"{frame_idx}: done {num_games} games, mean reward {mean_reward:.3f}, eps {epsilon:.2f}, speed {speed:.2f} f/s\")\n",
        "            writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "            writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "            writer.add_scalar(\"reward_100\", mean_reward, frame_idx)\n",
        "            writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "            # Save the mean reward to a file\n",
        "            if num_games % 100 == 0: # Save every 100 games\n",
        "                with open(mean_rewards_filepath, 'a') as f:\n",
        "                    f.write(f'{num_games},{mean_reward:.2f}\\n')\n",
        "                print(f'Mean reward for episode {num_games} saved to {mean_rewards_filepath}')\n",
        "\n",
        "            if best_mean_reward is None or best_mean_reward < mean_reward:\n",
        "                torch.save(net.state_dict(), args.env.replace(\"/\", \"_\") + \"-best.dat\")\n",
        "\n",
        "                if best_mean_reward is not None:\n",
        "                    print(\"Best mean reward updated %.3f -> %.3f, model saved\" % (best_mean_reward, mean_reward))\n",
        "                best_mean_reward = mean_reward\n",
        "            if mean_reward > args.reward:\n",
        "                print(\"Solved in %d frames!\" % frame_idx)\n",
        "                break\n",
        "\n",
        "        if len(buffer) < REPLAY_START_SIZE:\n",
        "            continue\n",
        "\n",
        "        if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "            tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch = buffer.sample(BATCH_SIZE)\n",
        "        loss_t = calc_loss(batch, net, tgt_net, device=device)\n",
        "        loss_t.backward()\n",
        "        optimizer.step()\n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "WyfRc5VqeQ9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5ac598-7e22-4d84-9783-5c95ce911dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "68: done 1 games, mean reward 35.000, eps 1.00, speed 246.45 f/s\n",
            "175: done 2 games, mean reward 40.000, eps 1.00, speed 229.71 f/s\n",
            "Best mean reward updated 35.000 -> 40.000, model saved\n",
            "272: done 3 games, mean reward 61.667, eps 1.00, speed 308.79 f/s\n",
            "Best mean reward updated 40.000 -> 61.667, model saved\n",
            "404: done 4 games, mean reward 68.750, eps 1.00, speed 238.01 f/s\n",
            "Best mean reward updated 61.667 -> 68.750, model saved\n",
            "472: done 5 games, mean reward 65.000, eps 1.00, speed 307.03 f/s\n",
            "569: done 6 games, mean reward 67.500, eps 0.99, speed 318.29 f/s\n",
            "734: done 7 games, mean reward 75.000, eps 0.99, speed 185.56 f/s\n",
            "Best mean reward updated 68.750 -> 75.000, model saved\n",
            "803: done 8 games, mean reward 66.250, eps 0.99, speed 121.78 f/s\n",
            "1027: done 9 games, mean reward 111.667, eps 0.99, speed 109.37 f/s\n",
            "Best mean reward updated 75.000 -> 111.667, model saved\n",
            "1149: done 10 games, mean reward 112.000, eps 0.99, speed 137.22 f/s\n",
            "Best mean reward updated 111.667 -> 112.000, model saved\n",
            "1360: done 11 games, mean reward 131.364, eps 0.99, speed 82.63 f/s\n",
            "Best mean reward updated 112.000 -> 131.364, model saved\n",
            "1531: done 12 games, mean reward 135.417, eps 0.98, speed 89.12 f/s\n",
            "Best mean reward updated 131.364 -> 135.417, model saved\n",
            "1624: done 13 games, mean reward 131.923, eps 0.98, speed 152.83 f/s\n",
            "1769: done 14 games, mean reward 132.143, eps 0.98, speed 339.30 f/s\n",
            "1892: done 15 games, mean reward 131.667, eps 0.98, speed 335.85 f/s\n",
            "2067: done 16 games, mean reward 149.688, eps 0.98, speed 329.89 f/s\n",
            "Best mean reward updated 135.417 -> 149.688, model saved\n",
            "2196: done 17 games, mean reward 147.647, eps 0.98, speed 333.81 f/s\n",
            "2320: done 18 games, mean reward 146.389, eps 0.98, speed 330.45 f/s\n",
            "2392: done 19 games, mean reward 139.474, eps 0.98, speed 306.12 f/s\n",
            "2582: done 20 games, mean reward 149.750, eps 0.97, speed 342.21 f/s\n",
            "Best mean reward updated 149.688 -> 149.750, model saved\n",
            "2800: done 21 games, mean reward 157.857, eps 0.97, speed 336.49 f/s\n",
            "Best mean reward updated 149.750 -> 157.857, model saved\n",
            "2871: done 22 games, mean reward 152.500, eps 0.97, speed 321.03 f/s\n",
            "2970: done 23 games, mean reward 149.565, eps 0.97, speed 324.17 f/s\n",
            "3043: done 24 games, mean reward 144.583, eps 0.97, speed 328.90 f/s\n",
            "3154: done 25 games, mean reward 141.800, eps 0.97, speed 340.26 f/s\n",
            "3363: done 26 games, mean reward 145.577, eps 0.97, speed 329.67 f/s\n",
            "3545: done 27 games, mean reward 150.185, eps 0.96, speed 340.21 f/s\n",
            "3681: done 28 games, mean reward 150.000, eps 0.96, speed 335.42 f/s\n",
            "3810: done 29 games, mean reward 152.069, eps 0.96, speed 337.64 f/s\n",
            "3898: done 30 games, mean reward 148.167, eps 0.96, speed 330.99 f/s\n",
            "4010: done 31 games, mean reward 145.968, eps 0.96, speed 325.74 f/s\n",
            "4158: done 32 games, mean reward 145.938, eps 0.96, speed 335.18 f/s\n",
            "4222: done 33 games, mean reward 143.182, eps 0.96, speed 319.29 f/s\n",
            "4380: done 34 games, mean reward 141.471, eps 0.96, speed 252.14 f/s\n",
            "4536: done 35 games, mean reward 141.714, eps 0.95, speed 214.49 f/s\n",
            "4698: done 36 games, mean reward 142.222, eps 0.95, speed 195.51 f/s\n",
            "4816: done 37 games, mean reward 141.216, eps 0.95, speed 238.37 f/s\n",
            "5031: done 38 games, mean reward 149.079, eps 0.95, speed 337.89 f/s\n",
            "5212: done 39 games, mean reward 152.821, eps 0.95, speed 344.61 f/s\n",
            "5377: done 40 games, mean reward 152.500, eps 0.95, speed 337.94 f/s\n",
            "5466: done 41 games, mean reward 148.902, eps 0.95, speed 308.32 f/s\n",
            "5551: done 42 games, mean reward 146.786, eps 0.94, speed 324.46 f/s\n",
            "5668: done 43 games, mean reward 144.651, eps 0.94, speed 333.21 f/s\n",
            "5762: done 44 games, mean reward 143.295, eps 0.94, speed 335.68 f/s\n",
            "5872: done 45 games, mean reward 141.889, eps 0.94, speed 316.92 f/s\n",
            "5981: done 46 games, mean reward 139.674, eps 0.94, speed 329.34 f/s\n",
            "6119: done 47 games, mean reward 143.830, eps 0.94, speed 329.68 f/s\n",
            "6185: done 48 games, mean reward 141.875, eps 0.94, speed 294.06 f/s\n",
            "6363: done 49 games, mean reward 143.061, eps 0.94, speed 345.08 f/s\n",
            "6484: done 50 games, mean reward 143.100, eps 0.94, speed 315.53 f/s\n",
            "6629: done 51 games, mean reward 142.549, eps 0.93, speed 321.33 f/s\n",
            "6796: done 52 games, mean reward 148.558, eps 0.93, speed 335.83 f/s\n",
            "6946: done 53 games, mean reward 148.679, eps 0.93, speed 324.74 f/s\n",
            "7085: done 54 games, mean reward 148.148, eps 0.93, speed 332.15 f/s\n",
            "7208: done 55 games, mean reward 147.364, eps 0.93, speed 316.28 f/s\n",
            "7347: done 56 games, mean reward 147.946, eps 0.93, speed 337.48 f/s\n",
            "7414: done 57 games, mean reward 146.667, eps 0.93, speed 294.37 f/s\n",
            "7554: done 58 games, mean reward 145.345, eps 0.92, speed 322.05 f/s\n",
            "7628: done 59 games, mean reward 143.475, eps 0.92, speed 297.40 f/s\n",
            "7723: done 60 games, mean reward 142.333, eps 0.92, speed 321.85 f/s\n",
            "7824: done 61 games, mean reward 140.902, eps 0.92, speed 318.19 f/s\n",
            "7944: done 62 games, mean reward 140.403, eps 0.92, speed 337.50 f/s\n",
            "8055: done 63 games, mean reward 138.968, eps 0.92, speed 272.66 f/s\n",
            "8171: done 64 games, mean reward 138.438, eps 0.92, speed 196.16 f/s\n",
            "8228: done 65 games, mean reward 136.692, eps 0.92, speed 185.53 f/s\n",
            "8358: done 66 games, mean reward 135.606, eps 0.92, speed 163.53 f/s\n",
            "8530: done 67 games, mean reward 136.791, eps 0.91, speed 234.06 f/s\n",
            "8653: done 68 games, mean reward 136.544, eps 0.91, speed 325.90 f/s\n",
            "8842: done 69 games, mean reward 138.406, eps 0.91, speed 341.44 f/s\n",
            "8969: done 70 games, mean reward 137.000, eps 0.91, speed 307.67 f/s\n",
            "9211: done 71 games, mean reward 138.944, eps 0.91, speed 330.68 f/s\n",
            "9313: done 72 games, mean reward 138.889, eps 0.91, speed 312.38 f/s\n",
            "9459: done 73 games, mean reward 139.452, eps 0.91, speed 288.86 f/s\n",
            "9565: done 74 games, mean reward 139.662, eps 0.90, speed 272.16 f/s\n",
            "9763: done 75 games, mean reward 144.267, eps 0.90, speed 286.64 f/s\n",
            "9855: done 76 games, mean reward 142.961, eps 0.90, speed 300.03 f/s\n",
            "10008: done 77 games, mean reward 142.792, eps 0.90, speed 147.02 f/s\n",
            "10160: done 78 games, mean reward 142.436, eps 0.90, speed 14.31 f/s\n",
            "10333: done 79 games, mean reward 142.911, eps 0.90, speed 14.50 f/s\n",
            "10435: done 80 games, mean reward 142.500, eps 0.90, speed 15.44 f/s\n",
            "10537: done 81 games, mean reward 141.914, eps 0.89, speed 13.86 f/s\n",
            "10652: done 82 games, mean reward 140.854, eps 0.89, speed 13.62 f/s\n",
            "10892: done 83 games, mean reward 142.952, eps 0.89, speed 12.62 f/s\n",
            "11015: done 84 games, mean reward 142.202, eps 0.89, speed 12.87 f/s\n",
            "11176: done 85 games, mean reward 142.529, eps 0.89, speed 11.41 f/s\n",
            "11280: done 86 games, mean reward 141.802, eps 0.89, speed 12.00 f/s\n",
            "11372: done 87 games, mean reward 140.517, eps 0.89, speed 13.96 f/s\n",
            "11562: done 88 games, mean reward 140.795, eps 0.88, speed 12.45 f/s\n",
            "11665: done 89 games, mean reward 140.112, eps 0.88, speed 13.42 f/s\n",
            "11841: done 90 games, mean reward 140.222, eps 0.88, speed 12.77 f/s\n",
            "11933: done 91 games, mean reward 139.780, eps 0.88, speed 12.37 f/s\n",
            "12036: done 92 games, mean reward 139.565, eps 0.88, speed 13.81 f/s\n",
            "12131: done 93 games, mean reward 139.194, eps 0.88, speed 14.79 f/s\n",
            "12224: done 94 games, mean reward 138.830, eps 0.88, speed 12.34 f/s\n",
            "12290: done 95 games, mean reward 137.684, eps 0.88, speed 14.92 f/s\n",
            "12389: done 96 games, mean reward 136.667, eps 0.88, speed 13.56 f/s\n",
            "12600: done 97 games, mean reward 138.969, eps 0.87, speed 14.61 f/s\n",
            "12734: done 98 games, mean reward 138.673, eps 0.87, speed 14.53 f/s\n",
            "12932: done 99 games, mean reward 139.646, eps 0.87, speed 14.41 f/s\n",
            "13085: done 100 games, mean reward 139.850, eps 0.87, speed 14.81 f/s\n",
            "Mean reward for episode 100 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "13160: done 101 games, mean reward 139.800, eps 0.87, speed 13.80 f/s\n",
            "13257: done 102 games, mean reward 140.150, eps 0.87, speed 13.78 f/s\n",
            "13481: done 103 games, mean reward 143.100, eps 0.87, speed 13.67 f/s\n",
            "13578: done 104 games, mean reward 143.000, eps 0.86, speed 13.21 f/s\n",
            "13772: done 105 games, mean reward 144.350, eps 0.86, speed 12.63 f/s\n",
            "13957: done 106 games, mean reward 145.800, eps 0.86, speed 13.27 f/s\n",
            "14138: done 107 games, mean reward 147.050, eps 0.86, speed 13.13 f/s\n",
            "14205: done 108 games, mean reward 147.300, eps 0.86, speed 13.68 f/s\n",
            "14324: done 109 games, mean reward 143.900, eps 0.86, speed 12.80 f/s\n",
            "14410: done 110 games, mean reward 143.350, eps 0.86, speed 12.49 f/s\n",
            "14530: done 111 games, mean reward 142.750, eps 0.85, speed 13.45 f/s\n",
            "14714: done 112 games, mean reward 142.800, eps 0.85, speed 12.76 f/s\n",
            "14812: done 113 games, mean reward 142.800, eps 0.85, speed 15.27 f/s\n",
            "14890: done 114 games, mean reward 142.000, eps 0.85, speed 13.47 f/s\n",
            "15041: done 115 games, mean reward 142.250, eps 0.85, speed 14.03 f/s\n",
            "15143: done 116 games, mean reward 138.700, eps 0.85, speed 13.62 f/s\n",
            "15265: done 117 games, mean reward 138.700, eps 0.85, speed 13.39 f/s\n",
            "15478: done 118 games, mean reward 139.850, eps 0.85, speed 13.03 f/s\n",
            "15572: done 119 games, mean reward 140.250, eps 0.84, speed 12.47 f/s\n",
            "15688: done 120 games, mean reward 137.450, eps 0.84, speed 12.98 f/s\n",
            "15875: done 121 games, mean reward 135.800, eps 0.84, speed 12.73 f/s\n",
            "15975: done 122 games, mean reward 136.750, eps 0.84, speed 13.74 f/s\n",
            "16121: done 123 games, mean reward 137.950, eps 0.84, speed 12.86 f/s\n",
            "16237: done 124 games, mean reward 138.850, eps 0.84, speed 12.66 f/s\n",
            "16417: done 125 games, mean reward 140.550, eps 0.84, speed 12.58 f/s\n",
            "16658: done 126 games, mean reward 140.600, eps 0.83, speed 11.89 f/s\n",
            "16742: done 127 games, mean reward 138.250, eps 0.83, speed 13.15 f/s\n",
            "16936: done 128 games, mean reward 138.350, eps 0.83, speed 12.14 f/s\n",
            "17118: done 129 games, mean reward 141.450, eps 0.83, speed 12.53 f/s\n",
            "17227: done 130 games, mean reward 142.600, eps 0.83, speed 12.51 f/s\n",
            "17312: done 131 games, mean reward 142.850, eps 0.83, speed 12.35 f/s\n",
            "17423: done 132 games, mean reward 142.150, eps 0.83, speed 12.14 f/s\n",
            "17514: done 133 games, mean reward 141.950, eps 0.82, speed 12.82 f/s\n",
            "17670: done 134 games, mean reward 143.300, eps 0.82, speed 12.31 f/s\n",
            "17762: done 135 games, mean reward 142.350, eps 0.82, speed 11.65 f/s\n",
            "17827: done 136 games, mean reward 141.050, eps 0.82, speed 12.48 f/s\n",
            "17897: done 137 games, mean reward 140.350, eps 0.82, speed 11.86 f/s\n",
            "18023: done 138 games, mean reward 138.100, eps 0.82, speed 12.52 f/s\n",
            "18097: done 139 games, mean reward 135.950, eps 0.82, speed 13.10 f/s\n",
            "18215: done 140 games, mean reward 135.450, eps 0.82, speed 12.24 f/s\n",
            "18319: done 141 games, mean reward 136.300, eps 0.82, speed 12.27 f/s\n",
            "18506: done 142 games, mean reward 138.800, eps 0.81, speed 12.69 f/s\n",
            "18700: done 143 games, mean reward 139.500, eps 0.81, speed 12.69 f/s\n",
            "18892: done 144 games, mean reward 140.750, eps 0.81, speed 12.59 f/s\n",
            "19115: done 145 games, mean reward 143.450, eps 0.81, speed 12.28 f/s\n",
            "19229: done 146 games, mean reward 143.550, eps 0.81, speed 12.39 f/s\n",
            "19323: done 147 games, mean reward 141.250, eps 0.81, speed 13.24 f/s\n",
            "19418: done 148 games, mean reward 141.200, eps 0.81, speed 12.27 f/s\n",
            "19559: done 149 games, mean reward 141.000, eps 0.80, speed 12.40 f/s\n",
            "19678: done 150 games, mean reward 139.950, eps 0.80, speed 12.81 f/s\n",
            "19807: done 151 games, mean reward 140.550, eps 0.80, speed 12.79 f/s\n",
            "19939: done 152 games, mean reward 138.100, eps 0.80, speed 12.42 f/s\n",
            "20012: done 153 games, mean reward 136.900, eps 0.80, speed 11.67 f/s\n",
            "20088: done 154 games, mean reward 136.350, eps 0.80, speed 12.69 f/s\n",
            "20249: done 155 games, mean reward 137.800, eps 0.80, speed 12.22 f/s\n",
            "20364: done 156 games, mean reward 137.250, eps 0.80, speed 12.16 f/s\n",
            "20545: done 157 games, mean reward 138.400, eps 0.79, speed 12.53 f/s\n",
            "20673: done 158 games, mean reward 138.650, eps 0.79, speed 12.35 f/s\n",
            "20904: done 159 games, mean reward 141.400, eps 0.79, speed 12.34 f/s\n",
            "21032: done 160 games, mean reward 141.050, eps 0.79, speed 12.70 f/s\n",
            "21161: done 161 games, mean reward 141.450, eps 0.79, speed 12.27 f/s\n",
            "21228: done 162 games, mean reward 141.050, eps 0.79, speed 11.53 f/s\n",
            "21306: done 163 games, mean reward 140.850, eps 0.79, speed 13.36 f/s\n",
            "21388: done 164 games, mean reward 140.500, eps 0.79, speed 12.06 f/s\n",
            "21452: done 165 games, mean reward 140.400, eps 0.79, speed 13.11 f/s\n",
            "21534: done 166 games, mean reward 139.950, eps 0.78, speed 11.88 f/s\n",
            "21653: done 167 games, mean reward 138.400, eps 0.78, speed 13.17 f/s\n",
            "21751: done 168 games, mean reward 138.250, eps 0.78, speed 12.25 f/s\n",
            "21818: done 169 games, mean reward 136.100, eps 0.78, speed 12.78 f/s\n",
            "21982: done 170 games, mean reward 138.200, eps 0.78, speed 12.47 f/s\n",
            "22080: done 171 games, mean reward 136.050, eps 0.78, speed 13.07 f/s\n",
            "22199: done 172 games, mean reward 135.850, eps 0.78, speed 12.27 f/s\n",
            "22355: done 173 games, mean reward 135.600, eps 0.78, speed 12.53 f/s\n",
            "22474: done 174 games, mean reward 135.400, eps 0.78, speed 12.09 f/s\n",
            "22716: done 175 games, mean reward 134.200, eps 0.77, speed 12.64 f/s\n",
            "22883: done 176 games, mean reward 134.250, eps 0.77, speed 12.45 f/s\n",
            "23003: done 177 games, mean reward 133.200, eps 0.77, speed 12.20 f/s\n",
            "23119: done 178 games, mean reward 133.250, eps 0.77, speed 12.27 f/s\n",
            "23250: done 179 games, mean reward 132.650, eps 0.77, speed 12.22 f/s\n",
            "23361: done 180 games, mean reward 132.950, eps 0.77, speed 12.09 f/s\n",
            "23601: done 181 games, mean reward 137.400, eps 0.76, speed 12.73 f/s\n",
            "23692: done 182 games, mean reward 137.350, eps 0.76, speed 12.04 f/s\n",
            "23753: done 183 games, mean reward 134.550, eps 0.76, speed 13.08 f/s\n",
            "23880: done 184 games, mean reward 134.100, eps 0.76, speed 12.20 f/s\n",
            "23958: done 185 games, mean reward 132.500, eps 0.76, speed 11.94 f/s\n",
            "24086: done 186 games, mean reward 132.200, eps 0.76, speed 12.53 f/s\n",
            "24172: done 187 games, mean reward 132.450, eps 0.76, speed 11.83 f/s\n",
            "24389: done 188 games, mean reward 131.900, eps 0.76, speed 12.89 f/s\n",
            "24514: done 189 games, mean reward 132.450, eps 0.75, speed 12.72 f/s\n",
            "24628: done 190 games, mean reward 131.300, eps 0.75, speed 12.77 f/s\n",
            "24842: done 191 games, mean reward 135.050, eps 0.75, speed 13.18 f/s\n",
            "25025: done 192 games, mean reward 137.050, eps 0.75, speed 12.95 f/s\n",
            "25128: done 193 games, mean reward 136.850, eps 0.75, speed 12.46 f/s\n",
            "25198: done 194 games, mean reward 136.050, eps 0.75, speed 13.58 f/s\n",
            "25320: done 195 games, mean reward 137.000, eps 0.75, speed 12.65 f/s\n",
            "25541: done 196 games, mean reward 139.000, eps 0.74, speed 12.66 f/s\n",
            "25648: done 197 games, mean reward 135.850, eps 0.74, speed 13.59 f/s\n",
            "25936: done 198 games, mean reward 138.700, eps 0.74, speed 12.94 f/s\n",
            "26110: done 199 games, mean reward 138.100, eps 0.74, speed 13.34 f/s\n",
            "26237: done 200 games, mean reward 137.600, eps 0.74, speed 13.79 f/s\n",
            "Mean reward for episode 200 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "26304: done 201 games, mean reward 137.450, eps 0.74, speed 14.54 f/s\n",
            "26484: done 202 games, mean reward 139.950, eps 0.74, speed 13.90 f/s\n",
            "26604: done 203 games, mean reward 137.300, eps 0.73, speed 13.59 f/s\n",
            "26692: done 204 games, mean reward 137.350, eps 0.73, speed 13.67 f/s\n",
            "26825: done 205 games, mean reward 137.250, eps 0.73, speed 14.52 f/s\n",
            "27022: done 206 games, mean reward 138.650, eps 0.73, speed 13.78 f/s\n",
            "27173: done 207 games, mean reward 137.850, eps 0.73, speed 13.25 f/s\n",
            "27294: done 208 games, mean reward 138.600, eps 0.73, speed 12.55 f/s\n",
            "27397: done 209 games, mean reward 137.850, eps 0.73, speed 12.80 f/s\n",
            "27569: done 210 games, mean reward 139.000, eps 0.72, speed 13.17 f/s\n",
            "27710: done 211 games, mean reward 138.450, eps 0.72, speed 13.04 f/s\n",
            "27779: done 212 games, mean reward 137.500, eps 0.72, speed 13.80 f/s\n",
            "27933: done 213 games, mean reward 138.500, eps 0.72, speed 12.51 f/s\n",
            "28007: done 214 games, mean reward 138.300, eps 0.72, speed 11.63 f/s\n",
            "28157: done 215 games, mean reward 138.550, eps 0.72, speed 12.51 f/s\n",
            "28351: done 216 games, mean reward 141.200, eps 0.72, speed 12.62 f/s\n",
            "28568: done 217 games, mean reward 142.750, eps 0.71, speed 12.79 f/s\n",
            "28685: done 218 games, mean reward 141.550, eps 0.71, speed 12.27 f/s\n",
            "28841: done 219 games, mean reward 142.750, eps 0.71, speed 12.30 f/s\n",
            "28943: done 220 games, mean reward 143.150, eps 0.71, speed 12.36 f/s\n",
            "29059: done 221 games, mean reward 142.550, eps 0.71, speed 12.79 f/s\n",
            "29183: done 222 games, mean reward 142.450, eps 0.71, speed 12.61 f/s\n",
            "29343: done 223 games, mean reward 144.500, eps 0.71, speed 12.45 f/s\n",
            "29470: done 224 games, mean reward 144.500, eps 0.71, speed 12.09 f/s\n",
            "29672: done 225 games, mean reward 144.950, eps 0.70, speed 12.30 f/s\n",
            "29756: done 226 games, mean reward 143.150, eps 0.70, speed 12.56 f/s\n",
            "29949: done 227 games, mean reward 145.200, eps 0.70, speed 12.60 f/s\n",
            "30148: done 228 games, mean reward 145.400, eps 0.70, speed 12.05 f/s\n",
            "30307: done 229 games, mean reward 142.350, eps 0.70, speed 12.35 f/s\n",
            "30438: done 230 games, mean reward 141.650, eps 0.70, speed 12.12 f/s\n",
            "30554: done 231 games, mean reward 141.350, eps 0.69, speed 12.82 f/s\n",
            "30681: done 232 games, mean reward 141.650, eps 0.69, speed 12.16 f/s\n",
            "30932: done 233 games, mean reward 144.550, eps 0.69, speed 12.21 f/s\n",
            "31076: done 234 games, mean reward 143.700, eps 0.69, speed 12.28 f/s\n",
            "31189: done 235 games, mean reward 143.800, eps 0.69, speed 12.50 f/s\n",
            "31313: done 236 games, mean reward 145.000, eps 0.69, speed 12.81 f/s\n",
            "31470: done 237 games, mean reward 145.700, eps 0.69, speed 12.32 f/s\n",
            "31699: done 238 games, mean reward 146.000, eps 0.68, speed 12.15 f/s\n",
            "31814: done 239 games, mean reward 145.500, eps 0.68, speed 11.82 f/s\n",
            "32010: done 240 games, mean reward 149.950, eps 0.68, speed 12.46 f/s\n",
            "32119: done 241 games, mean reward 150.150, eps 0.68, speed 12.17 f/s\n",
            "32252: done 242 games, mean reward 147.850, eps 0.68, speed 12.58 f/s\n",
            "32502: done 243 games, mean reward 149.050, eps 0.67, speed 12.28 f/s\n",
            "32674: done 244 games, mean reward 149.250, eps 0.67, speed 12.25 f/s\n",
            "32856: done 245 games, mean reward 149.200, eps 0.67, speed 11.83 f/s\n",
            "32926: done 246 games, mean reward 149.500, eps 0.67, speed 12.47 f/s\n",
            "33082: done 247 games, mean reward 150.250, eps 0.67, speed 12.13 f/s\n",
            "33295: done 248 games, mean reward 152.300, eps 0.67, speed 12.03 f/s\n",
            "33359: done 249 games, mean reward 150.550, eps 0.67, speed 12.11 f/s\n",
            "33475: done 250 games, mean reward 150.650, eps 0.67, speed 12.05 f/s\n",
            "33629: done 251 games, mean reward 150.700, eps 0.66, speed 11.93 f/s\n",
            "33748: done 252 games, mean reward 149.900, eps 0.66, speed 12.03 f/s\n",
            "33805: done 253 games, mean reward 149.600, eps 0.66, speed 12.35 f/s\n",
            "33885: done 254 games, mean reward 149.000, eps 0.66, speed 12.27 f/s\n",
            "33974: done 255 games, mean reward 147.500, eps 0.66, speed 11.80 f/s\n",
            "34154: done 256 games, mean reward 147.300, eps 0.66, speed 12.41 f/s\n",
            "34260: done 257 games, mean reward 145.750, eps 0.66, speed 11.99 f/s\n",
            "34488: done 258 games, mean reward 148.300, eps 0.66, speed 12.31 f/s\n",
            "34615: done 259 games, mean reward 145.950, eps 0.65, speed 12.19 f/s\n",
            "34742: done 260 games, mean reward 146.650, eps 0.65, speed 11.86 f/s\n",
            "34877: done 261 games, mean reward 147.050, eps 0.65, speed 12.13 f/s\n",
            "34994: done 262 games, mean reward 146.750, eps 0.65, speed 11.51 f/s\n",
            "35220: done 263 games, mean reward 148.900, eps 0.65, speed 11.58 f/s\n",
            "35392: done 264 games, mean reward 150.550, eps 0.65, speed 11.28 f/s\n",
            "35485: done 265 games, mean reward 151.100, eps 0.65, speed 11.61 f/s\n",
            "35589: done 266 games, mean reward 152.400, eps 0.64, speed 10.87 f/s\n",
            "35660: done 267 games, mean reward 152.200, eps 0.64, speed 10.70 f/s\n",
            "35778: done 268 games, mean reward 151.900, eps 0.64, speed 12.28 f/s\n",
            "35960: done 269 games, mean reward 154.600, eps 0.64, speed 11.39 f/s\n",
            "36140: done 270 games, mean reward 154.300, eps 0.64, speed 11.92 f/s\n",
            "36253: done 271 games, mean reward 154.200, eps 0.64, speed 11.71 f/s\n",
            "36428: done 272 games, mean reward 155.400, eps 0.64, speed 12.01 f/s\n",
            "36612: done 273 games, mean reward 156.000, eps 0.63, speed 12.04 f/s\n",
            "36738: done 274 games, mean reward 156.200, eps 0.63, speed 11.68 f/s\n",
            "36982: done 275 games, mean reward 157.450, eps 0.63, speed 11.58 f/s\n",
            "37195: done 276 games, mean reward 159.350, eps 0.63, speed 11.97 f/s\n",
            "Best mean reward updated 157.857 -> 159.350, model saved\n",
            "37322: done 277 games, mean reward 160.900, eps 0.63, speed 11.65 f/s\n",
            "Best mean reward updated 159.350 -> 160.900, model saved\n",
            "37494: done 278 games, mean reward 162.250, eps 0.63, speed 11.87 f/s\n",
            "Best mean reward updated 160.900 -> 162.250, model saved\n",
            "37564: done 279 games, mean reward 161.650, eps 0.62, speed 11.00 f/s\n",
            "37632: done 280 games, mean reward 161.000, eps 0.62, speed 12.31 f/s\n",
            "37774: done 281 games, mean reward 157.550, eps 0.62, speed 11.66 f/s\n",
            "37874: done 282 games, mean reward 158.150, eps 0.62, speed 11.45 f/s\n",
            "37947: done 283 games, mean reward 158.350, eps 0.62, speed 12.26 f/s\n",
            "38137: done 284 games, mean reward 160.700, eps 0.62, speed 11.75 f/s\n",
            "38266: done 285 games, mean reward 161.800, eps 0.62, speed 12.48 f/s\n",
            "38367: done 286 games, mean reward 162.650, eps 0.62, speed 11.59 f/s\n",
            "Best mean reward updated 162.250 -> 162.650, model saved\n",
            "38473: done 287 games, mean reward 162.850, eps 0.62, speed 11.60 f/s\n",
            "Best mean reward updated 162.650 -> 162.850, model saved\n",
            "38610: done 288 games, mean reward 163.500, eps 0.61, speed 11.90 f/s\n",
            "Best mean reward updated 162.850 -> 163.500, model saved\n",
            "38749: done 289 games, mean reward 163.000, eps 0.61, speed 11.77 f/s\n",
            "38921: done 290 games, mean reward 164.450, eps 0.61, speed 12.14 f/s\n",
            "Best mean reward updated 163.500 -> 164.450, model saved\n",
            "39043: done 291 games, mean reward 160.750, eps 0.61, speed 11.90 f/s\n",
            "39178: done 292 games, mean reward 159.450, eps 0.61, speed 12.28 f/s\n",
            "39396: done 293 games, mean reward 160.900, eps 0.61, speed 12.45 f/s\n",
            "39569: done 294 games, mean reward 164.900, eps 0.60, speed 12.42 f/s\n",
            "Best mean reward updated 164.450 -> 164.900, model saved\n",
            "39704: done 295 games, mean reward 165.250, eps 0.60, speed 12.24 f/s\n",
            "Best mean reward updated 164.900 -> 165.250, model saved\n",
            "39776: done 296 games, mean reward 163.300, eps 0.60, speed 12.18 f/s\n",
            "39900: done 297 games, mean reward 164.200, eps 0.60, speed 12.68 f/s\n",
            "40078: done 298 games, mean reward 162.350, eps 0.60, speed 12.15 f/s\n",
            "40209: done 299 games, mean reward 161.650, eps 0.60, speed 12.69 f/s\n",
            "40334: done 300 games, mean reward 162.600, eps 0.60, speed 12.14 f/s\n",
            "Mean reward for episode 300 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "40469: done 301 games, mean reward 163.450, eps 0.60, speed 12.34 f/s\n",
            "40629: done 302 games, mean reward 161.650, eps 0.59, speed 12.50 f/s\n",
            "40708: done 303 games, mean reward 160.650, eps 0.59, speed 11.85 f/s\n",
            "40881: done 304 games, mean reward 162.800, eps 0.59, speed 12.62 f/s\n",
            "40978: done 305 games, mean reward 162.200, eps 0.59, speed 13.61 f/s\n",
            "41122: done 306 games, mean reward 159.900, eps 0.59, speed 12.66 f/s\n",
            "41185: done 307 games, mean reward 158.550, eps 0.59, speed 11.73 f/s\n",
            "41314: done 308 games, mean reward 158.900, eps 0.59, speed 12.92 f/s\n",
            "41385: done 309 games, mean reward 158.650, eps 0.59, speed 12.68 f/s\n",
            "41509: done 310 games, mean reward 158.400, eps 0.58, speed 12.63 f/s\n",
            "41617: done 311 games, mean reward 157.100, eps 0.58, speed 13.41 f/s\n",
            "41693: done 312 games, mean reward 156.500, eps 0.58, speed 11.77 f/s\n",
            "41851: done 313 games, mean reward 158.550, eps 0.58, speed 12.36 f/s\n",
            "41963: done 314 games, mean reward 159.050, eps 0.58, speed 12.43 f/s\n",
            "42217: done 315 games, mean reward 159.900, eps 0.58, speed 12.80 f/s\n",
            "42334: done 316 games, mean reward 158.400, eps 0.58, speed 12.12 f/s\n",
            "42411: done 317 games, mean reward 156.250, eps 0.58, speed 11.42 f/s\n",
            "42524: done 318 games, mean reward 156.150, eps 0.57, speed 13.25 f/s\n",
            "42720: done 319 games, mean reward 157.700, eps 0.57, speed 12.32 f/s\n",
            "42833: done 320 games, mean reward 157.350, eps 0.57, speed 12.99 f/s\n",
            "43002: done 321 games, mean reward 157.750, eps 0.57, speed 12.77 f/s\n",
            "43171: done 322 games, mean reward 158.550, eps 0.57, speed 12.43 f/s\n",
            "43402: done 323 games, mean reward 159.700, eps 0.57, speed 12.34 f/s\n",
            "43554: done 324 games, mean reward 160.600, eps 0.56, speed 12.49 f/s\n",
            "43707: done 325 games, mean reward 158.950, eps 0.56, speed 12.53 f/s\n",
            "43909: done 326 games, mean reward 160.400, eps 0.56, speed 12.40 f/s\n",
            "44010: done 327 games, mean reward 158.550, eps 0.56, speed 11.97 f/s\n",
            "44106: done 328 games, mean reward 157.150, eps 0.56, speed 12.84 f/s\n",
            "44288: done 329 games, mean reward 157.250, eps 0.56, speed 12.46 f/s\n",
            "44416: done 330 games, mean reward 158.250, eps 0.56, speed 12.99 f/s\n",
            "44592: done 331 games, mean reward 160.000, eps 0.55, speed 12.32 f/s\n",
            "44691: done 332 games, mean reward 159.450, eps 0.55, speed 13.18 f/s\n",
            "44818: done 333 games, mean reward 157.250, eps 0.55, speed 12.43 f/s\n",
            "44912: done 334 games, mean reward 156.550, eps 0.55, speed 12.02 f/s\n",
            "45068: done 335 games, mean reward 157.300, eps 0.55, speed 12.67 f/s\n",
            "45198: done 336 games, mean reward 156.950, eps 0.55, speed 12.88 f/s\n",
            "45269: done 337 games, mean reward 156.500, eps 0.55, speed 12.30 f/s\n",
            "45392: done 338 games, mean reward 155.850, eps 0.55, speed 12.58 f/s\n",
            "45471: done 339 games, mean reward 156.450, eps 0.55, speed 13.23 f/s\n",
            "45607: done 340 games, mean reward 152.150, eps 0.54, speed 12.38 f/s\n",
            "45687: done 341 games, mean reward 151.450, eps 0.54, speed 11.97 f/s\n",
            "45928: done 342 games, mean reward 154.350, eps 0.54, speed 12.93 f/s\n",
            "46114: done 343 games, mean reward 154.500, eps 0.54, speed 12.76 f/s\n",
            "46210: done 344 games, mean reward 153.250, eps 0.54, speed 12.15 f/s\n",
            "46324: done 345 games, mean reward 150.450, eps 0.54, speed 12.35 f/s\n",
            "46440: done 346 games, mean reward 150.700, eps 0.54, speed 13.08 f/s\n",
            "46503: done 347 games, mean reward 149.050, eps 0.53, speed 11.78 f/s\n",
            "46687: done 348 games, mean reward 149.200, eps 0.53, speed 12.86 f/s\n",
            "46844: done 349 games, mean reward 150.900, eps 0.53, speed 12.73 f/s\n",
            "47007: done 350 games, mean reward 151.850, eps 0.53, speed 12.68 f/s\n",
            "47077: done 351 games, mean reward 150.700, eps 0.53, speed 12.58 f/s\n",
            "47225: done 352 games, mean reward 150.900, eps 0.53, speed 13.03 f/s\n",
            "47311: done 353 games, mean reward 152.100, eps 0.53, speed 12.30 f/s\n",
            "47428: done 354 games, mean reward 152.600, eps 0.53, speed 12.53 f/s\n",
            "47543: done 355 games, mean reward 152.650, eps 0.52, speed 13.41 f/s\n",
            "47708: done 356 games, mean reward 152.750, eps 0.52, speed 12.53 f/s\n",
            "47782: done 357 games, mean reward 152.650, eps 0.52, speed 12.55 f/s\n",
            "47907: done 358 games, mean reward 150.400, eps 0.52, speed 12.61 f/s\n",
            "48042: done 359 games, mean reward 150.200, eps 0.52, speed 12.75 f/s\n",
            "48195: done 360 games, mean reward 152.800, eps 0.52, speed 12.74 f/s\n",
            "48370: done 361 games, mean reward 152.850, eps 0.52, speed 12.81 f/s\n",
            "48483: done 362 games, mean reward 154.150, eps 0.52, speed 13.43 f/s\n",
            "48696: done 363 games, mean reward 154.750, eps 0.51, speed 12.45 f/s\n",
            "48770: done 364 games, mean reward 152.850, eps 0.51, speed 13.26 f/s\n",
            "48848: done 365 games, mean reward 152.300, eps 0.51, speed 12.19 f/s\n",
            "48940: done 366 games, mean reward 151.050, eps 0.51, speed 13.34 f/s\n",
            "49062: done 367 games, mean reward 153.100, eps 0.51, speed 12.55 f/s\n",
            "49170: done 368 games, mean reward 153.250, eps 0.51, speed 12.36 f/s\n",
            "49231: done 369 games, mean reward 150.150, eps 0.51, speed 13.63 f/s\n",
            "49322: done 370 games, mean reward 148.700, eps 0.51, speed 12.27 f/s\n",
            "49498: done 371 games, mean reward 150.450, eps 0.51, speed 12.75 f/s\n",
            "49647: done 372 games, mean reward 149.650, eps 0.50, speed 12.57 f/s\n",
            "49849: done 373 games, mean reward 153.500, eps 0.50, speed 13.41 f/s\n",
            "50065: done 374 games, mean reward 153.900, eps 0.50, speed 13.40 f/s\n",
            "50132: done 375 games, mean reward 149.300, eps 0.50, speed 12.24 f/s\n",
            "50283: done 376 games, mean reward 148.400, eps 0.50, speed 13.07 f/s\n",
            "50412: done 377 games, mean reward 147.050, eps 0.50, speed 13.65 f/s\n",
            "50532: done 378 games, mean reward 145.650, eps 0.49, speed 12.41 f/s\n",
            "50703: done 379 games, mean reward 147.150, eps 0.49, speed 12.78 f/s\n",
            "50917: done 380 games, mean reward 147.600, eps 0.49, speed 12.61 f/s\n",
            "51041: done 381 games, mean reward 147.500, eps 0.49, speed 13.39 f/s\n",
            "51172: done 382 games, mean reward 147.650, eps 0.49, speed 12.73 f/s\n",
            "51297: done 383 games, mean reward 147.850, eps 0.49, speed 12.87 f/s\n",
            "51392: done 384 games, mean reward 145.900, eps 0.49, speed 13.05 f/s\n",
            "51627: done 385 games, mean reward 152.150, eps 0.48, speed 13.73 f/s\n",
            "51826: done 386 games, mean reward 152.500, eps 0.48, speed 13.66 f/s\n",
            "52017: done 387 games, mean reward 154.350, eps 0.48, speed 13.76 f/s\n",
            "52107: done 388 games, mean reward 154.050, eps 0.48, speed 12.81 f/s\n",
            "52211: done 389 games, mean reward 154.000, eps 0.48, speed 14.23 f/s\n",
            "52334: done 390 games, mean reward 153.800, eps 0.48, speed 13.22 f/s\n",
            "52428: done 391 games, mean reward 153.450, eps 0.48, speed 13.13 f/s\n",
            "52547: done 392 games, mean reward 152.450, eps 0.47, speed 14.22 f/s\n",
            "52786: done 393 games, mean reward 153.700, eps 0.47, speed 13.04 f/s\n",
            "52853: done 394 games, mean reward 149.750, eps 0.47, speed 14.00 f/s\n",
            "53051: done 395 games, mean reward 153.000, eps 0.47, speed 12.82 f/s\n",
            "53182: done 396 games, mean reward 153.850, eps 0.47, speed 13.29 f/s\n",
            "53247: done 397 games, mean reward 152.800, eps 0.47, speed 12.01 f/s\n",
            "53443: done 398 games, mean reward 153.550, eps 0.47, speed 13.58 f/s\n",
            "53591: done 399 games, mean reward 154.950, eps 0.46, speed 13.39 f/s\n",
            "53754: done 400 games, mean reward 154.300, eps 0.46, speed 13.38 f/s\n",
            "Mean reward for episode 400 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "53903: done 401 games, mean reward 154.800, eps 0.46, speed 13.11 f/s\n",
            "54033: done 402 games, mean reward 154.150, eps 0.46, speed 13.92 f/s\n",
            "54155: done 403 games, mean reward 155.250, eps 0.46, speed 13.34 f/s\n",
            "54251: done 404 games, mean reward 153.000, eps 0.46, speed 12.62 f/s\n",
            "54369: done 405 games, mean reward 153.300, eps 0.46, speed 13.64 f/s\n",
            "54539: done 406 games, mean reward 157.700, eps 0.45, speed 13.15 f/s\n",
            "54702: done 407 games, mean reward 159.700, eps 0.45, speed 13.17 f/s\n",
            "54882: done 408 games, mean reward 159.850, eps 0.45, speed 13.12 f/s\n",
            "55034: done 409 games, mean reward 161.600, eps 0.45, speed 13.61 f/s\n",
            "55138: done 410 games, mean reward 161.600, eps 0.45, speed 13.77 f/s\n",
            "55256: done 411 games, mean reward 161.400, eps 0.45, speed 13.16 f/s\n",
            "55469: done 412 games, mean reward 163.850, eps 0.45, speed 13.46 f/s\n",
            "55660: done 413 games, mean reward 161.300, eps 0.44, speed 13.31 f/s\n",
            "55737: done 414 games, mean reward 161.500, eps 0.44, speed 12.65 f/s\n",
            "55923: done 415 games, mean reward 163.150, eps 0.44, speed 13.69 f/s\n",
            "56009: done 416 games, mean reward 162.300, eps 0.44, speed 14.34 f/s\n",
            "56191: done 417 games, mean reward 163.600, eps 0.44, speed 13.33 f/s\n",
            "56268: done 418 games, mean reward 162.950, eps 0.44, speed 13.36 f/s\n",
            "56431: done 419 games, mean reward 161.250, eps 0.44, speed 13.46 f/s\n",
            "56619: done 420 games, mean reward 162.600, eps 0.43, speed 13.36 f/s\n",
            "56706: done 421 games, mean reward 162.350, eps 0.43, speed 12.92 f/s\n",
            "56809: done 422 games, mean reward 160.750, eps 0.43, speed 14.05 f/s\n",
            "56928: done 423 games, mean reward 157.450, eps 0.43, speed 12.94 f/s\n",
            "57141: done 424 games, mean reward 159.300, eps 0.43, speed 13.66 f/s\n",
            "57205: done 425 games, mean reward 158.450, eps 0.43, speed 12.39 f/s\n",
            "57304: done 426 games, mean reward 157.600, eps 0.43, speed 14.05 f/s\n",
            "57541: done 427 games, mean reward 159.250, eps 0.42, speed 13.31 f/s\n",
            "57637: done 428 games, mean reward 159.750, eps 0.42, speed 14.27 f/s\n",
            "57699: done 429 games, mean reward 157.850, eps 0.42, speed 12.05 f/s\n",
            "57839: done 430 games, mean reward 157.000, eps 0.42, speed 13.40 f/s\n",
            "57960: done 431 games, mean reward 155.850, eps 0.42, speed 13.05 f/s\n",
            "58040: done 432 games, mean reward 155.650, eps 0.42, speed 12.34 f/s\n",
            "58253: done 433 games, mean reward 158.600, eps 0.42, speed 13.14 f/s\n",
            "58381: done 434 games, mean reward 159.600, eps 0.42, speed 12.64 f/s\n",
            "58510: done 435 games, mean reward 159.500, eps 0.41, speed 12.46 f/s\n",
            "58599: done 436 games, mean reward 159.700, eps 0.41, speed 13.01 f/s\n",
            "58727: done 437 games, mean reward 160.700, eps 0.41, speed 12.40 f/s\n",
            "58853: done 438 games, mean reward 160.550, eps 0.41, speed 12.56 f/s\n",
            "59054: done 439 games, mean reward 162.200, eps 0.41, speed 12.93 f/s\n",
            "59160: done 440 games, mean reward 162.450, eps 0.41, speed 12.63 f/s\n",
            "59444: done 441 games, mean reward 168.150, eps 0.41, speed 13.19 f/s\n",
            "Best mean reward updated 165.250 -> 168.150, model saved\n",
            "59579: done 442 games, mean reward 164.950, eps 0.40, speed 13.79 f/s\n",
            "59693: done 443 games, mean reward 162.900, eps 0.40, speed 13.10 f/s\n",
            "59796: done 444 games, mean reward 162.450, eps 0.40, speed 13.00 f/s\n",
            "60003: done 445 games, mean reward 163.850, eps 0.40, speed 13.55 f/s\n",
            "60179: done 446 games, mean reward 164.200, eps 0.40, speed 13.67 f/s\n",
            "60372: done 447 games, mean reward 169.150, eps 0.40, speed 13.52 f/s\n",
            "Best mean reward updated 168.150 -> 169.150, model saved\n",
            "60476: done 448 games, mean reward 167.550, eps 0.40, speed 13.31 f/s\n",
            "60673: done 449 games, mean reward 167.950, eps 0.39, speed 13.76 f/s\n",
            "60741: done 450 games, mean reward 167.250, eps 0.39, speed 14.48 f/s\n",
            "60816: done 451 games, mean reward 167.050, eps 0.39, speed 12.89 f/s\n",
            "61054: done 452 games, mean reward 168.200, eps 0.39, speed 13.86 f/s\n",
            "61188: done 453 games, mean reward 168.050, eps 0.39, speed 13.62 f/s\n",
            "61357: done 454 games, mean reward 169.650, eps 0.39, speed 13.73 f/s\n",
            "Best mean reward updated 169.150 -> 169.650, model saved\n",
            "61516: done 455 games, mean reward 170.350, eps 0.38, speed 13.59 f/s\n",
            "Best mean reward updated 169.650 -> 170.350, model saved\n",
            "61595: done 456 games, mean reward 169.300, eps 0.38, speed 14.66 f/s\n",
            "61769: done 457 games, mean reward 170.600, eps 0.38, speed 13.80 f/s\n",
            "Best mean reward updated 170.350 -> 170.600, model saved\n",
            "61868: done 458 games, mean reward 170.100, eps 0.38, speed 13.34 f/s\n",
            "62022: done 459 games, mean reward 173.950, eps 0.38, speed 13.26 f/s\n",
            "Best mean reward updated 170.600 -> 173.950, model saved\n",
            "62138: done 460 games, mean reward 172.150, eps 0.38, speed 13.12 f/s\n",
            "62338: done 461 games, mean reward 173.400, eps 0.38, speed 13.41 f/s\n",
            "62519: done 462 games, mean reward 173.600, eps 0.37, speed 13.47 f/s\n",
            "62668: done 463 games, mean reward 174.700, eps 0.37, speed 13.18 f/s\n",
            "Best mean reward updated 173.950 -> 174.700, model saved\n",
            "62815: done 464 games, mean reward 177.450, eps 0.37, speed 13.23 f/s\n",
            "Best mean reward updated 174.700 -> 177.450, model saved\n",
            "63045: done 465 games, mean reward 180.100, eps 0.37, speed 13.51 f/s\n",
            "Best mean reward updated 177.450 -> 180.100, model saved\n",
            "63156: done 466 games, mean reward 180.900, eps 0.37, speed 13.29 f/s\n",
            "Best mean reward updated 180.100 -> 180.900, model saved\n",
            "63270: done 467 games, mean reward 179.500, eps 0.37, speed 14.19 f/s\n",
            "63363: done 468 games, mean reward 179.250, eps 0.37, speed 13.10 f/s\n",
            "63562: done 469 games, mean reward 182.650, eps 0.36, speed 13.36 f/s\n",
            "Best mean reward updated 180.900 -> 182.650, model saved\n",
            "63636: done 470 games, mean reward 182.800, eps 0.36, speed 12.48 f/s\n",
            "Best mean reward updated 182.650 -> 182.800, model saved\n",
            "63732: done 471 games, mean reward 180.950, eps 0.36, speed 14.28 f/s\n",
            "63900: done 472 games, mean reward 182.700, eps 0.36, speed 13.14 f/s\n",
            "64090: done 473 games, mean reward 177.600, eps 0.36, speed 13.44 f/s\n",
            "64215: done 474 games, mean reward 176.650, eps 0.36, speed 13.29 f/s\n",
            "64361: done 475 games, mean reward 177.550, eps 0.36, speed 13.32 f/s\n",
            "64486: done 476 games, mean reward 177.200, eps 0.36, speed 13.20 f/s\n",
            "64706: done 477 games, mean reward 180.500, eps 0.35, speed 13.63 f/s\n",
            "64853: done 478 games, mean reward 181.550, eps 0.35, speed 13.34 f/s\n",
            "65081: done 479 games, mean reward 181.550, eps 0.35, speed 13.61 f/s\n",
            "65208: done 480 games, mean reward 181.500, eps 0.35, speed 13.13 f/s\n",
            "65310: done 481 games, mean reward 180.500, eps 0.35, speed 13.02 f/s\n",
            "65457: done 482 games, mean reward 180.850, eps 0.35, speed 13.42 f/s\n",
            "65569: done 483 games, mean reward 180.900, eps 0.34, speed 13.88 f/s\n",
            "65709: done 484 games, mean reward 181.750, eps 0.34, speed 13.18 f/s\n",
            "65827: done 485 games, mean reward 176.600, eps 0.34, speed 12.96 f/s\n",
            "65979: done 486 games, mean reward 177.100, eps 0.34, speed 13.22 f/s\n",
            "66194: done 487 games, mean reward 177.800, eps 0.34, speed 13.31 f/s\n",
            "66335: done 488 games, mean reward 177.500, eps 0.34, speed 13.13 f/s\n",
            "66418: done 489 games, mean reward 177.750, eps 0.34, speed 13.16 f/s\n",
            "66542: done 490 games, mean reward 176.900, eps 0.33, speed 13.72 f/s\n",
            "66666: done 491 games, mean reward 177.000, eps 0.33, speed 13.29 f/s\n",
            "66858: done 492 games, mean reward 178.150, eps 0.33, speed 13.52 f/s\n",
            "66929: done 493 games, mean reward 174.700, eps 0.33, speed 12.78 f/s\n",
            "67012: done 494 games, mean reward 174.550, eps 0.33, speed 14.13 f/s\n",
            "67202: done 495 games, mean reward 171.700, eps 0.33, speed 13.14 f/s\n",
            "67316: done 496 games, mean reward 171.650, eps 0.33, speed 12.83 f/s\n",
            "67437: done 497 games, mean reward 172.900, eps 0.33, speed 12.76 f/s\n",
            "67631: done 498 games, mean reward 171.800, eps 0.32, speed 13.16 f/s\n",
            "67775: done 499 games, mean reward 174.000, eps 0.32, speed 12.98 f/s\n",
            "67903: done 500 games, mean reward 174.000, eps 0.32, speed 12.79 f/s\n",
            "Mean reward for episode 500 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "68026: done 501 games, mean reward 173.800, eps 0.32, speed 13.68 f/s\n",
            "68261: done 502 games, mean reward 176.850, eps 0.32, speed 12.77 f/s\n",
            "68446: done 503 games, mean reward 180.900, eps 0.32, speed 13.34 f/s\n",
            "68676: done 504 games, mean reward 183.550, eps 0.31, speed 13.52 f/s\n",
            "Best mean reward updated 182.800 -> 183.550, model saved\n",
            "68837: done 505 games, mean reward 183.600, eps 0.31, speed 13.22 f/s\n",
            "Best mean reward updated 183.550 -> 183.600, model saved\n",
            "68904: done 506 games, mean reward 178.750, eps 0.31, speed 12.16 f/s\n",
            "69096: done 507 games, mean reward 178.550, eps 0.31, speed 12.89 f/s\n",
            "69267: done 508 games, mean reward 178.200, eps 0.31, speed 13.12 f/s\n",
            "69383: done 509 games, mean reward 177.450, eps 0.31, speed 12.91 f/s\n",
            "69551: done 510 games, mean reward 177.850, eps 0.30, speed 13.17 f/s\n",
            "69676: done 511 games, mean reward 178.050, eps 0.30, speed 13.15 f/s\n",
            "69858: done 512 games, mean reward 178.950, eps 0.30, speed 13.38 f/s\n",
            "70081: done 513 games, mean reward 181.350, eps 0.30, speed 13.22 f/s\n",
            "70352: done 514 games, mean reward 185.700, eps 0.30, speed 13.01 f/s\n",
            "Best mean reward updated 183.600 -> 185.700, model saved\n",
            "70472: done 515 games, mean reward 183.250, eps 0.30, speed 13.04 f/s\n",
            "70703: done 516 games, mean reward 186.500, eps 0.29, speed 13.22 f/s\n",
            "Best mean reward updated 185.700 -> 186.500, model saved\n",
            "70824: done 517 games, mean reward 185.850, eps 0.29, speed 12.80 f/s\n",
            "70923: done 518 games, mean reward 185.750, eps 0.29, speed 13.86 f/s\n",
            "71056: done 519 games, mean reward 185.400, eps 0.29, speed 12.96 f/s\n",
            "71153: done 520 games, mean reward 183.650, eps 0.29, speed 12.63 f/s\n",
            "71233: done 521 games, mean reward 183.600, eps 0.29, speed 13.56 f/s\n",
            "71402: done 522 games, mean reward 186.250, eps 0.29, speed 13.05 f/s\n",
            "71579: done 523 games, mean reward 185.900, eps 0.28, speed 13.01 f/s\n",
            "71699: done 524 games, mean reward 183.050, eps 0.28, speed 12.75 f/s\n",
            "71835: done 525 games, mean reward 185.150, eps 0.28, speed 12.71 f/s\n",
            "71960: done 526 games, mean reward 185.850, eps 0.28, speed 12.41 f/s\n",
            "72141: done 527 games, mean reward 184.950, eps 0.28, speed 12.76 f/s\n",
            "72249: done 528 games, mean reward 185.000, eps 0.28, speed 12.60 f/s\n",
            "72412: done 529 games, mean reward 186.450, eps 0.28, speed 12.93 f/s\n",
            "72533: done 530 games, mean reward 186.850, eps 0.27, speed 13.29 f/s\n",
            "Best mean reward updated 186.500 -> 186.850, model saved\n",
            "72739: done 531 games, mean reward 188.000, eps 0.27, speed 12.69 f/s\n",
            "Best mean reward updated 186.850 -> 188.000, model saved\n",
            "72913: done 532 games, mean reward 189.500, eps 0.27, speed 12.69 f/s\n",
            "Best mean reward updated 188.000 -> 189.500, model saved\n",
            "73101: done 533 games, mean reward 188.850, eps 0.27, speed 12.86 f/s\n",
            "73277: done 534 games, mean reward 188.900, eps 0.27, speed 12.83 f/s\n",
            "73405: done 535 games, mean reward 189.250, eps 0.27, speed 12.43 f/s\n",
            "73504: done 536 games, mean reward 188.200, eps 0.26, speed 12.28 f/s\n",
            "73595: done 537 games, mean reward 187.400, eps 0.26, speed 13.10 f/s\n",
            "73743: done 538 games, mean reward 188.150, eps 0.26, speed 12.52 f/s\n",
            "73868: done 539 games, mean reward 186.950, eps 0.26, speed 12.25 f/s\n",
            "73988: done 540 games, mean reward 187.150, eps 0.26, speed 12.43 f/s\n",
            "74273: done 541 games, mean reward 187.450, eps 0.26, speed 12.58 f/s\n",
            "74401: done 542 games, mean reward 187.950, eps 0.26, speed 13.40 f/s\n",
            "74482: done 543 games, mean reward 187.800, eps 0.26, speed 12.24 f/s\n",
            "74634: done 544 games, mean reward 189.350, eps 0.25, speed 12.74 f/s\n",
            "74764: done 545 games, mean reward 188.500, eps 0.25, speed 12.82 f/s\n",
            "74953: done 546 games, mean reward 191.900, eps 0.25, speed 12.91 f/s\n",
            "Best mean reward updated 189.500 -> 191.900, model saved\n",
            "75122: done 547 games, mean reward 188.300, eps 0.25, speed 12.69 f/s\n",
            "75278: done 548 games, mean reward 189.100, eps 0.25, speed 12.60 f/s\n",
            "75410: done 549 games, mean reward 188.400, eps 0.25, speed 12.72 f/s\n",
            "75466: done 550 games, mean reward 187.950, eps 0.25, speed 13.23 f/s\n",
            "75560: done 551 games, mean reward 188.350, eps 0.24, speed 12.29 f/s\n",
            "75658: done 552 games, mean reward 186.800, eps 0.24, speed 13.18 f/s\n",
            "75794: done 553 games, mean reward 187.150, eps 0.24, speed 12.75 f/s\n",
            "75861: done 554 games, mean reward 185.450, eps 0.24, speed 11.90 f/s\n",
            "76054: done 555 games, mean reward 186.100, eps 0.24, speed 12.74 f/s\n",
            "76291: done 556 games, mean reward 187.900, eps 0.24, speed 12.27 f/s\n",
            "76358: done 557 games, mean reward 186.850, eps 0.24, speed 12.55 f/s\n",
            "76490: done 558 games, mean reward 187.350, eps 0.24, speed 12.27 f/s\n",
            "76565: done 559 games, mean reward 183.700, eps 0.23, speed 13.33 f/s\n",
            "76658: done 560 games, mean reward 182.900, eps 0.23, speed 12.16 f/s\n",
            "76825: done 561 games, mean reward 181.800, eps 0.23, speed 12.44 f/s\n",
            "76983: done 562 games, mean reward 182.050, eps 0.23, speed 12.42 f/s\n",
            "77151: done 563 games, mean reward 180.200, eps 0.23, speed 12.45 f/s\n",
            "77287: done 564 games, mean reward 178.550, eps 0.23, speed 12.40 f/s\n",
            "77443: done 565 games, mean reward 178.100, eps 0.23, speed 12.51 f/s\n",
            "77541: done 566 games, mean reward 177.500, eps 0.22, speed 12.00 f/s\n",
            "77752: done 567 games, mean reward 177.900, eps 0.22, speed 12.51 f/s\n",
            "77968: done 568 games, mean reward 179.800, eps 0.22, speed 12.24 f/s\n",
            "78178: done 569 games, mean reward 181.000, eps 0.22, speed 12.19 f/s\n",
            "78321: done 570 games, mean reward 181.550, eps 0.22, speed 12.03 f/s\n",
            "78485: done 571 games, mean reward 184.550, eps 0.22, speed 12.18 f/s\n",
            "78700: done 572 games, mean reward 183.750, eps 0.21, speed 12.17 f/s\n",
            "78896: done 573 games, mean reward 188.050, eps 0.21, speed 11.89 f/s\n",
            "79057: done 574 games, mean reward 188.950, eps 0.21, speed 12.06 f/s\n",
            "79197: done 575 games, mean reward 189.750, eps 0.21, speed 11.98 f/s\n",
            "79317: done 576 games, mean reward 190.650, eps 0.21, speed 12.07 f/s\n",
            "79430: done 577 games, mean reward 188.600, eps 0.21, speed 12.36 f/s\n",
            "79547: done 578 games, mean reward 186.950, eps 0.20, speed 11.88 f/s\n",
            "79671: done 579 games, mean reward 185.900, eps 0.20, speed 12.06 f/s\n",
            "79826: done 580 games, mean reward 186.850, eps 0.20, speed 12.09 f/s\n",
            "80032: done 581 games, mean reward 188.550, eps 0.20, speed 12.03 f/s\n",
            "80280: done 582 games, mean reward 192.250, eps 0.20, speed 11.91 f/s\n",
            "Best mean reward updated 191.900 -> 192.250, model saved\n",
            "80392: done 583 games, mean reward 192.700, eps 0.20, speed 11.76 f/s\n",
            "Best mean reward updated 192.250 -> 192.700, model saved\n",
            "80573: done 584 games, mean reward 192.700, eps 0.19, speed 11.98 f/s\n",
            "80750: done 585 games, mean reward 192.400, eps 0.19, speed 11.95 f/s\n",
            "80813: done 586 games, mean reward 190.550, eps 0.19, speed 11.17 f/s\n",
            "80928: done 587 games, mean reward 188.350, eps 0.19, speed 11.78 f/s\n",
            "81040: done 588 games, mean reward 189.000, eps 0.19, speed 12.36 f/s\n",
            "81214: done 589 games, mean reward 191.400, eps 0.19, speed 11.55 f/s\n",
            "81309: done 590 games, mean reward 191.500, eps 0.19, speed 12.09 f/s\n",
            "81372: done 591 games, mean reward 191.650, eps 0.19, speed 11.15 f/s\n",
            "81566: done 592 games, mean reward 192.700, eps 0.18, speed 11.97 f/s\n",
            "81742: done 593 games, mean reward 195.900, eps 0.18, speed 11.91 f/s\n",
            "Best mean reward updated 192.700 -> 195.900, model saved\n",
            "81953: done 594 games, mean reward 197.550, eps 0.18, speed 11.48 f/s\n",
            "Best mean reward updated 195.900 -> 197.550, model saved\n",
            "82097: done 595 games, mean reward 197.250, eps 0.18, speed 11.65 f/s\n",
            "82222: done 596 games, mean reward 197.750, eps 0.18, speed 11.96 f/s\n",
            "Best mean reward updated 197.550 -> 197.750, model saved\n",
            "82374: done 597 games, mean reward 198.550, eps 0.18, speed 11.76 f/s\n",
            "Best mean reward updated 197.750 -> 198.550, model saved\n",
            "82492: done 598 games, mean reward 197.300, eps 0.18, speed 12.24 f/s\n",
            "82624: done 599 games, mean reward 194.850, eps 0.17, speed 11.65 f/s\n",
            "82715: done 600 games, mean reward 193.950, eps 0.17, speed 11.11 f/s\n",
            "Mean reward for episode 600 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "82817: done 601 games, mean reward 193.200, eps 0.17, speed 11.30 f/s\n",
            "82993: done 602 games, mean reward 190.450, eps 0.17, speed 11.59 f/s\n",
            "83121: done 603 games, mean reward 186.250, eps 0.17, speed 11.23 f/s\n",
            "83254: done 604 games, mean reward 184.450, eps 0.17, speed 11.49 f/s\n",
            "83432: done 605 games, mean reward 188.050, eps 0.17, speed 11.52 f/s\n",
            "83566: done 606 games, mean reward 188.450, eps 0.16, speed 11.64 f/s\n",
            "83722: done 607 games, mean reward 188.600, eps 0.16, speed 11.68 f/s\n",
            "83933: done 608 games, mean reward 188.550, eps 0.16, speed 11.65 f/s\n",
            "84117: done 609 games, mean reward 190.400, eps 0.16, speed 11.44 f/s\n",
            "84201: done 610 games, mean reward 189.400, eps 0.16, speed 12.09 f/s\n",
            "84298: done 611 games, mean reward 189.800, eps 0.16, speed 11.54 f/s\n",
            "84522: done 612 games, mean reward 191.900, eps 0.15, speed 11.53 f/s\n",
            "84615: done 613 games, mean reward 189.450, eps 0.15, speed 12.17 f/s\n",
            "84743: done 614 games, mean reward 185.600, eps 0.15, speed 11.64 f/s\n",
            "84867: done 615 games, mean reward 185.000, eps 0.15, speed 11.51 f/s\n",
            "84933: done 616 games, mean reward 181.450, eps 0.15, speed 11.11 f/s\n",
            "85060: done 617 games, mean reward 181.850, eps 0.15, speed 12.20 f/s\n",
            "85265: done 618 games, mean reward 183.750, eps 0.15, speed 11.54 f/s\n",
            "85540: done 619 games, mean reward 187.350, eps 0.14, speed 11.72 f/s\n",
            "85744: done 620 games, mean reward 188.550, eps 0.14, speed 11.85 f/s\n",
            "85864: done 621 games, mean reward 188.100, eps 0.14, speed 11.50 f/s\n",
            "85994: done 622 games, mean reward 185.750, eps 0.14, speed 11.65 f/s\n",
            "86142: done 623 games, mean reward 185.650, eps 0.14, speed 11.60 f/s\n",
            "86206: done 624 games, mean reward 185.100, eps 0.14, speed 11.61 f/s\n",
            "86360: done 625 games, mean reward 185.650, eps 0.14, speed 11.35 f/s\n",
            "86480: done 626 games, mean reward 184.200, eps 0.14, speed 12.06 f/s\n",
            "86548: done 627 games, mean reward 183.450, eps 0.13, speed 11.14 f/s\n",
            "86716: done 628 games, mean reward 184.350, eps 0.13, speed 11.46 f/s\n",
            "86919: done 629 games, mean reward 186.050, eps 0.13, speed 11.40 f/s\n",
            "87052: done 630 games, mean reward 186.100, eps 0.13, speed 11.49 f/s\n",
            "87207: done 631 games, mean reward 184.750, eps 0.13, speed 11.11 f/s\n",
            "87328: done 632 games, mean reward 183.750, eps 0.13, speed 11.54 f/s\n",
            "87453: done 633 games, mean reward 181.100, eps 0.13, speed 11.61 f/s\n",
            "87543: done 634 games, mean reward 180.050, eps 0.12, speed 11.13 f/s\n",
            "87713: done 635 games, mean reward 179.800, eps 0.12, speed 11.41 f/s\n",
            "87835: done 636 games, mean reward 181.000, eps 0.12, speed 11.17 f/s\n",
            "87959: done 637 games, mean reward 181.900, eps 0.12, speed 11.27 f/s\n",
            "88074: done 638 games, mean reward 180.400, eps 0.12, speed 11.31 f/s\n",
            "88168: done 639 games, mean reward 180.300, eps 0.12, speed 11.46 f/s\n",
            "88231: done 640 games, mean reward 179.150, eps 0.12, speed 11.40 f/s\n",
            "88499: done 641 games, mean reward 179.150, eps 0.12, speed 11.31 f/s\n",
            "88573: done 642 games, mean reward 178.450, eps 0.11, speed 11.65 f/s\n",
            "88720: done 643 games, mean reward 181.850, eps 0.11, speed 11.12 f/s\n",
            "88970: done 644 games, mean reward 183.450, eps 0.11, speed 11.49 f/s\n",
            "89172: done 645 games, mean reward 183.750, eps 0.11, speed 11.25 f/s\n",
            "89355: done 646 games, mean reward 179.800, eps 0.11, speed 11.55 f/s\n",
            "89541: done 647 games, mean reward 179.950, eps 0.10, speed 11.40 f/s\n",
            "89719: done 648 games, mean reward 179.000, eps 0.10, speed 11.08 f/s\n",
            "89848: done 649 games, mean reward 178.850, eps 0.10, speed 11.23 f/s\n",
            "89970: done 650 games, mean reward 180.000, eps 0.10, speed 11.66 f/s\n",
            "90082: done 651 games, mean reward 179.950, eps 0.10, speed 11.37 f/s\n",
            "90212: done 652 games, mean reward 179.950, eps 0.10, speed 11.18 f/s\n",
            "90435: done 653 games, mean reward 182.300, eps 0.10, speed 11.15 f/s\n",
            "90587: done 654 games, mean reward 184.500, eps 0.09, speed 11.46 f/s\n",
            "90696: done 655 games, mean reward 183.250, eps 0.09, speed 11.33 f/s\n",
            "90822: done 656 games, mean reward 182.650, eps 0.09, speed 11.44 f/s\n",
            "90935: done 657 games, mean reward 182.950, eps 0.09, speed 11.85 f/s\n",
            "91070: done 658 games, mean reward 182.900, eps 0.09, speed 11.48 f/s\n",
            "91243: done 659 games, mean reward 183.600, eps 0.09, speed 11.17 f/s\n",
            "91391: done 660 games, mean reward 184.650, eps 0.09, speed 11.33 f/s\n",
            "91506: done 661 games, mean reward 185.700, eps 0.08, speed 11.40 f/s\n",
            "91622: done 662 games, mean reward 184.300, eps 0.08, speed 11.85 f/s\n",
            "91878: done 663 games, mean reward 187.300, eps 0.08, speed 11.42 f/s\n",
            "91994: done 664 games, mean reward 186.300, eps 0.08, speed 11.18 f/s\n",
            "92091: done 665 games, mean reward 185.150, eps 0.08, speed 10.93 f/s\n",
            "92205: done 666 games, mean reward 185.750, eps 0.08, speed 11.26 f/s\n",
            "92378: done 667 games, mean reward 186.900, eps 0.08, speed 11.45 f/s\n",
            "92457: done 668 games, mean reward 185.150, eps 0.08, speed 11.63 f/s\n",
            "92580: done 669 games, mean reward 182.400, eps 0.07, speed 11.29 f/s\n",
            "92754: done 670 games, mean reward 183.550, eps 0.07, speed 11.15 f/s\n",
            "92845: done 671 games, mean reward 180.700, eps 0.07, speed 11.79 f/s\n",
            "93084: done 672 games, mean reward 182.050, eps 0.07, speed 11.23 f/s\n",
            "93290: done 673 games, mean reward 181.950, eps 0.07, speed 11.58 f/s\n",
            "93490: done 674 games, mean reward 181.650, eps 0.07, speed 11.32 f/s\n",
            "93598: done 675 games, mean reward 180.500, eps 0.06, speed 11.24 f/s\n",
            "93718: done 676 games, mean reward 179.800, eps 0.06, speed 11.84 f/s\n",
            "93843: done 677 games, mean reward 180.150, eps 0.06, speed 11.47 f/s\n",
            "93974: done 678 games, mean reward 181.050, eps 0.06, speed 11.36 f/s\n",
            "94045: done 679 games, mean reward 180.600, eps 0.06, speed 10.99 f/s\n",
            "94236: done 680 games, mean reward 182.750, eps 0.06, speed 11.27 f/s\n",
            "94391: done 681 games, mean reward 181.300, eps 0.06, speed 11.12 f/s\n",
            "94543: done 682 games, mean reward 180.100, eps 0.05, speed 11.25 f/s\n",
            "94725: done 683 games, mean reward 180.650, eps 0.05, speed 11.07 f/s\n",
            "94850: done 684 games, mean reward 180.800, eps 0.05, speed 11.23 f/s\n",
            "94969: done 685 games, mean reward 180.350, eps 0.05, speed 11.04 f/s\n",
            "95134: done 686 games, mean reward 182.300, eps 0.05, speed 11.24 f/s\n",
            "95274: done 687 games, mean reward 183.400, eps 0.05, speed 11.42 f/s\n",
            "95395: done 688 games, mean reward 183.650, eps 0.05, speed 11.14 f/s\n",
            "95694: done 689 games, mean reward 183.800, eps 0.04, speed 11.30 f/s\n",
            "95848: done 690 games, mean reward 185.000, eps 0.04, speed 11.31 f/s\n",
            "95984: done 691 games, mean reward 186.150, eps 0.04, speed 11.20 f/s\n",
            "96224: done 692 games, mean reward 185.500, eps 0.04, speed 11.15 f/s\n",
            "96410: done 693 games, mean reward 184.800, eps 0.04, speed 11.44 f/s\n",
            "96567: done 694 games, mean reward 184.900, eps 0.03, speed 11.22 f/s\n",
            "96696: done 695 games, mean reward 185.050, eps 0.03, speed 11.28 f/s\n",
            "96897: done 696 games, mean reward 186.350, eps 0.03, speed 11.09 f/s\n",
            "97112: done 697 games, mean reward 186.050, eps 0.03, speed 11.42 f/s\n",
            "97327: done 698 games, mean reward 189.650, eps 0.03, speed 11.05 f/s\n",
            "97436: done 699 games, mean reward 188.000, eps 0.03, speed 10.80 f/s\n",
            "97678: done 700 games, mean reward 190.700, eps 0.02, speed 11.20 f/s\n",
            "Mean reward for episode 700 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "97873: done 701 games, mean reward 193.450, eps 0.02, speed 10.87 f/s\n",
            "98051: done 702 games, mean reward 195.000, eps 0.02, speed 10.84 f/s\n",
            "98173: done 703 games, mean reward 195.350, eps 0.02, speed 10.99 f/s\n",
            "98356: done 704 games, mean reward 195.500, eps 0.02, speed 11.39 f/s\n",
            "98475: done 705 games, mean reward 192.200, eps 0.02, speed 11.20 f/s\n",
            "98632: done 706 games, mean reward 194.300, eps 0.02, speed 11.32 f/s\n",
            "98810: done 707 games, mean reward 194.050, eps 0.02, speed 10.88 f/s\n",
            "98936: done 708 games, mean reward 194.000, eps 0.02, speed 11.05 f/s\n",
            "99188: done 709 games, mean reward 197.700, eps 0.02, speed 11.10 f/s\n",
            "99369: done 710 games, mean reward 198.450, eps 0.02, speed 11.00 f/s\n",
            "99540: done 711 games, mean reward 200.100, eps 0.02, speed 11.33 f/s\n",
            "Best mean reward updated 198.550 -> 200.100, model saved\n",
            "99700: done 712 games, mean reward 196.450, eps 0.02, speed 11.27 f/s\n",
            "99959: done 713 games, mean reward 200.350, eps 0.02, speed 11.21 f/s\n",
            "Best mean reward updated 200.100 -> 200.350, model saved\n",
            "100033: done 714 games, mean reward 199.600, eps 0.02, speed 10.64 f/s\n",
            "100169: done 715 games, mean reward 200.500, eps 0.02, speed 11.37 f/s\n",
            "Best mean reward updated 200.350 -> 200.500, model saved\n",
            "100240: done 716 games, mean reward 200.450, eps 0.02, speed 11.76 f/s\n",
            "100370: done 717 games, mean reward 200.400, eps 0.02, speed 11.26 f/s\n",
            "100581: done 718 games, mean reward 201.850, eps 0.02, speed 10.97 f/s\n",
            "Best mean reward updated 200.500 -> 201.850, model saved\n",
            "100651: done 719 games, mean reward 197.900, eps 0.02, speed 11.39 f/s\n",
            "100810: done 720 games, mean reward 197.100, eps 0.02, speed 11.19 f/s\n",
            "100940: done 721 games, mean reward 197.100, eps 0.02, speed 11.10 f/s\n",
            "101056: done 722 games, mean reward 198.250, eps 0.02, speed 11.11 f/s\n",
            "101213: done 723 games, mean reward 199.500, eps 0.02, speed 11.31 f/s\n",
            "101376: done 724 games, mean reward 201.450, eps 0.02, speed 11.20 f/s\n",
            "101479: done 725 games, mean reward 198.950, eps 0.02, speed 11.19 f/s\n",
            "101570: done 726 games, mean reward 199.000, eps 0.02, speed 11.04 f/s\n",
            "101691: done 727 games, mean reward 200.100, eps 0.02, speed 11.09 f/s\n",
            "101783: done 728 games, mean reward 198.800, eps 0.02, speed 11.77 f/s\n",
            "101985: done 729 games, mean reward 198.750, eps 0.02, speed 11.04 f/s\n",
            "102076: done 730 games, mean reward 197.800, eps 0.02, speed 11.14 f/s\n",
            "102252: done 731 games, mean reward 199.250, eps 0.02, speed 11.24 f/s\n",
            "102445: done 732 games, mean reward 202.000, eps 0.02, speed 11.46 f/s\n",
            "Best mean reward updated 201.850 -> 202.000, model saved\n",
            "102676: done 733 games, mean reward 205.800, eps 0.02, speed 11.23 f/s\n",
            "Best mean reward updated 202.000 -> 205.800, model saved\n",
            "102877: done 734 games, mean reward 208.550, eps 0.02, speed 11.48 f/s\n",
            "Best mean reward updated 205.800 -> 208.550, model saved\n",
            "103008: done 735 games, mean reward 209.900, eps 0.02, speed 11.07 f/s\n",
            "Best mean reward updated 208.550 -> 209.900, model saved\n",
            "103128: done 736 games, mean reward 209.950, eps 0.02, speed 11.17 f/s\n",
            "Best mean reward updated 209.900 -> 209.950, model saved\n",
            "103297: done 737 games, mean reward 210.650, eps 0.02, speed 11.52 f/s\n",
            "Best mean reward updated 209.950 -> 210.650, model saved\n",
            "103405: done 738 games, mean reward 210.350, eps 0.02, speed 11.34 f/s\n",
            "103636: done 739 games, mean reward 215.000, eps 0.02, speed 11.07 f/s\n",
            "Best mean reward updated 210.650 -> 215.000, model saved\n",
            "103825: done 740 games, mean reward 217.600, eps 0.02, speed 11.54 f/s\n",
            "Best mean reward updated 215.000 -> 217.600, model saved\n",
            "103971: done 741 games, mean reward 213.250, eps 0.02, speed 11.35 f/s\n",
            "104231: done 742 games, mean reward 219.400, eps 0.02, speed 11.28 f/s\n",
            "Best mean reward updated 217.600 -> 219.400, model saved\n",
            "104354: done 743 games, mean reward 217.400, eps 0.02, speed 11.22 f/s\n",
            "104529: done 744 games, mean reward 218.150, eps 0.02, speed 11.45 f/s\n",
            "104597: done 745 games, mean reward 217.400, eps 0.02, speed 10.98 f/s\n",
            "104714: done 746 games, mean reward 217.450, eps 0.02, speed 11.21 f/s\n",
            "104819: done 747 games, mean reward 217.250, eps 0.02, speed 11.87 f/s\n",
            "104948: done 748 games, mean reward 217.600, eps 0.02, speed 11.29 f/s\n",
            "105068: done 749 games, mean reward 217.750, eps 0.02, speed 10.89 f/s\n",
            "105202: done 750 games, mean reward 219.000, eps 0.02, speed 10.94 f/s\n",
            "105361: done 751 games, mean reward 220.750, eps 0.02, speed 11.21 f/s\n",
            "Best mean reward updated 219.400 -> 220.750, model saved\n",
            "105484: done 752 games, mean reward 220.950, eps 0.02, speed 11.09 f/s\n",
            "Best mean reward updated 220.750 -> 220.950, model saved\n",
            "105601: done 753 games, mean reward 218.900, eps 0.02, speed 10.94 f/s\n",
            "105825: done 754 games, mean reward 219.200, eps 0.02, speed 10.57 f/s\n",
            "105986: done 755 games, mean reward 220.450, eps 0.02, speed 10.94 f/s\n",
            "106233: done 756 games, mean reward 223.700, eps 0.02, speed 10.88 f/s\n",
            "Best mean reward updated 220.950 -> 223.700, model saved\n",
            "106444: done 757 games, mean reward 226.750, eps 0.02, speed 10.99 f/s\n",
            "Best mean reward updated 223.700 -> 226.750, model saved\n",
            "106621: done 758 games, mean reward 228.450, eps 0.02, speed 11.02 f/s\n",
            "Best mean reward updated 226.750 -> 228.450, model saved\n",
            "106737: done 759 games, mean reward 227.700, eps 0.02, speed 11.08 f/s\n",
            "106968: done 760 games, mean reward 230.050, eps 0.02, speed 11.36 f/s\n",
            "Best mean reward updated 228.450 -> 230.050, model saved\n",
            "107140: done 761 games, mean reward 230.300, eps 0.02, speed 10.87 f/s\n",
            "Best mean reward updated 230.050 -> 230.300, model saved\n",
            "107322: done 762 games, mean reward 232.900, eps 0.02, speed 11.16 f/s\n",
            "Best mean reward updated 230.300 -> 232.900, model saved\n",
            "107445: done 763 games, mean reward 229.100, eps 0.02, speed 11.12 f/s\n",
            "107612: done 764 games, mean reward 232.450, eps 0.02, speed 11.06 f/s\n",
            "107742: done 765 games, mean reward 232.500, eps 0.02, speed 10.91 f/s\n",
            "107909: done 766 games, mean reward 236.200, eps 0.02, speed 11.14 f/s\n",
            "Best mean reward updated 232.900 -> 236.200, model saved\n",
            "108075: done 767 games, mean reward 235.700, eps 0.02, speed 10.98 f/s\n",
            "108193: done 768 games, mean reward 237.200, eps 0.02, speed 11.37 f/s\n",
            "Best mean reward updated 236.200 -> 237.200, model saved\n",
            "108325: done 769 games, mean reward 237.400, eps 0.02, speed 11.00 f/s\n",
            "Best mean reward updated 237.200 -> 237.400, model saved\n",
            "108506: done 770 games, mean reward 237.450, eps 0.02, speed 10.68 f/s\n",
            "Best mean reward updated 237.400 -> 237.450, model saved\n",
            "108624: done 771 games, mean reward 238.900, eps 0.02, speed 10.78 f/s\n",
            "Best mean reward updated 237.450 -> 238.900, model saved\n",
            "108776: done 772 games, mean reward 237.250, eps 0.02, speed 11.04 f/s\n",
            "108936: done 773 games, mean reward 234.400, eps 0.02, speed 11.37 f/s\n",
            "109066: done 774 games, mean reward 236.600, eps 0.02, speed 11.06 f/s\n",
            "109220: done 775 games, mean reward 237.300, eps 0.02, speed 11.29 f/s\n",
            "109384: done 776 games, mean reward 238.900, eps 0.02, speed 11.18 f/s\n",
            "109580: done 777 games, mean reward 240.600, eps 0.02, speed 11.13 f/s\n",
            "Best mean reward updated 238.900 -> 240.600, model saved\n",
            "109809: done 778 games, mean reward 242.800, eps 0.02, speed 11.31 f/s\n",
            "Best mean reward updated 240.600 -> 242.800, model saved\n",
            "109873: done 779 games, mean reward 243.350, eps 0.02, speed 10.73 f/s\n",
            "Best mean reward updated 242.800 -> 243.350, model saved\n",
            "109944: done 780 games, mean reward 239.600, eps 0.02, speed 11.63 f/s\n",
            "110036: done 781 games, mean reward 239.800, eps 0.02, speed 11.06 f/s\n",
            "110210: done 782 games, mean reward 238.950, eps 0.02, speed 11.35 f/s\n",
            "110363: done 783 games, mean reward 238.900, eps 0.02, speed 11.27 f/s\n",
            "110651: done 784 games, mean reward 242.850, eps 0.02, speed 11.26 f/s\n",
            "110726: done 785 games, mean reward 242.300, eps 0.02, speed 10.64 f/s\n",
            "110925: done 786 games, mean reward 243.550, eps 0.02, speed 11.12 f/s\n",
            "Best mean reward updated 243.350 -> 243.550, model saved\n",
            "111000: done 787 games, mean reward 242.400, eps 0.02, speed 10.94 f/s\n",
            "111142: done 788 games, mean reward 241.700, eps 0.02, speed 11.09 f/s\n",
            "111261: done 789 games, mean reward 239.950, eps 0.02, speed 11.00 f/s\n",
            "111387: done 790 games, mean reward 239.250, eps 0.02, speed 11.15 f/s\n",
            "111572: done 791 games, mean reward 240.550, eps 0.02, speed 11.33 f/s\n",
            "111665: done 792 games, mean reward 239.600, eps 0.02, speed 10.81 f/s\n",
            "111867: done 793 games, mean reward 240.450, eps 0.02, speed 11.46 f/s\n",
            "111986: done 794 games, mean reward 240.150, eps 0.02, speed 11.07 f/s\n",
            "112179: done 795 games, mean reward 241.150, eps 0.02, speed 10.95 f/s\n",
            "112248: done 796 games, mean reward 238.650, eps 0.02, speed 11.78 f/s\n",
            "112357: done 797 games, mean reward 237.600, eps 0.02, speed 10.91 f/s\n",
            "112441: done 798 games, mean reward 233.850, eps 0.02, speed 10.82 f/s\n",
            "112631: done 799 games, mean reward 237.400, eps 0.02, speed 11.15 f/s\n",
            "112841: done 800 games, mean reward 237.400, eps 0.02, speed 11.01 f/s\n",
            "Mean reward for episode 800 saved to ALE_SpaceInvaders-v5_mean_rewards.csv\n",
            "112939: done 801 games, mean reward 235.150, eps 0.02, speed 11.52 f/s\n",
            "113056: done 802 games, mean reward 234.150, eps 0.02, speed 10.92 f/s\n",
            "113158: done 803 games, mean reward 233.550, eps 0.02, speed 11.00 f/s\n",
            "113296: done 804 games, mean reward 233.800, eps 0.02, speed 11.25 f/s\n",
            "113428: done 805 games, mean reward 234.000, eps 0.02, speed 11.17 f/s\n",
            "113565: done 806 games, mean reward 232.050, eps 0.02, speed 11.18 f/s\n",
            "113742: done 807 games, mean reward 232.250, eps 0.02, speed 11.31 f/s\n",
            "113854: done 808 games, mean reward 232.550, eps 0.02, speed 11.10 f/s\n",
            "114051: done 809 games, mean reward 227.400, eps 0.02, speed 11.39 f/s\n",
            "114174: done 810 games, mean reward 227.100, eps 0.02, speed 11.12 f/s\n",
            "114368: done 811 games, mean reward 228.300, eps 0.02, speed 11.01 f/s\n",
            "114486: done 812 games, mean reward 228.050, eps 0.02, speed 11.27 f/s\n",
            "114758: done 813 games, mean reward 229.250, eps 0.02, speed 11.15 f/s\n",
            "114938: done 814 games, mean reward 231.700, eps 0.02, speed 11.24 f/s\n",
            "115119: done 815 games, mean reward 234.800, eps 0.02, speed 11.27 f/s\n",
            "115306: done 816 games, mean reward 238.100, eps 0.02, speed 11.01 f/s\n",
            "115444: done 817 games, mean reward 238.550, eps 0.02, speed 11.23 f/s\n",
            "115591: done 818 games, mean reward 236.200, eps 0.02, speed 11.25 f/s\n",
            "115712: done 819 games, mean reward 237.400, eps 0.02, speed 11.27 f/s\n",
            "115863: done 820 games, mean reward 238.100, eps 0.02, speed 11.09 f/s\n",
            "115956: done 821 games, mean reward 239.000, eps 0.02, speed 11.80 f/s\n",
            "116071: done 822 games, mean reward 237.600, eps 0.02, speed 11.13 f/s\n",
            "116140: done 823 games, mean reward 235.900, eps 0.02, speed 10.84 f/s\n",
            "116256: done 824 games, mean reward 234.500, eps 0.02, speed 11.38 f/s\n",
            "116449: done 825 games, mean reward 236.850, eps 0.02, speed 11.11 f/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FARqxpfRglwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data And Retrain"
      ],
      "metadata": {
        "id": "J7ChImTPkQdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model weights\n",
        "model_path = args.env + \"-best.dat\"\n",
        "if os.path.exists(model_path):\n",
        "    net.load_state_dict(torch.load(model_path))\n",
        "    print(f\"Loaded model weights from {model_path}\")\n",
        "else:\n",
        "    print(f\"No saved model found at {model_path}, starting training from scratch.\")"
      ],
      "metadata": {
        "id": "42EpXb0Vgkaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}