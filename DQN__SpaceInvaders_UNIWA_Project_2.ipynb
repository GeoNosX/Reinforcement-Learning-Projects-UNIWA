{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5JOD1mUZoKFg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gymnasium[atari,accept-rom-license]\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pChd49s7TONN",
        "outputId": "88c567d3-fed5-4c2f-82fc-62b0cc4b5dac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPtthya-TC12",
        "outputId": "54ed0199-0b3f-47c0-b191-77855bf4b324"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.12/dist-packages (from ale-py) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorboardX"
      ],
      "metadata": {
        "id": "LJjE2Tufo_bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d5a31ab-e713-40aa-cb39-e598f0a7cd44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3c7wUf6ETrko"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "from tensorboardX import SummaryWriter\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super().__init__(env)\n",
        "        self.n_steps = n_steps\n",
        "        self.dtype = dtype\n",
        "        self.frames = collections.deque(maxlen=n_steps)\n",
        "\n",
        "        # AtariPreprocessing without channel_first=True outputs (H, W)\n",
        "        obs_shape = env.observation_space.shape # (84, 84)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(n_steps, obs_shape[0], obs_shape[1]), # Desired shape (4, 84, 84)\n",
        "            dtype=dtype\n",
        "        )\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs) # obs is (84, 84)\n",
        "        # Initialize deque with the first observation repeated n_steps times\n",
        "        for _ in range(self.n_steps):\n",
        "            self.frames.append(obs)\n",
        "        return self._get_observation(), info # Return observation and info\n",
        "\n",
        "    def observation(self, observation): # observation is (84, 84)\n",
        "        self.frames.append(observation)\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        # Stack frames along a new dimension (channel dimension) to get (n_steps, H, W)\n",
        "        return np.stack(list(self.frames), axis=0).astype(self.dtype)"
      ],
      "metadata": {
        "id": "RVLY5grLSemx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.wrappers import (\n",
        "    AtariPreprocessing,\n",
        "    TransformObservation,\n",
        "    RecordEpisodeStatistics\n",
        ")\n",
        "env = gym.make(\"ALE/SpaceInvaders-v5\", render_mode=\"rgb_array\", frameskip=1)\n",
        "# Apply AtariPreprocessing to convert to grayscale and resize frames\n",
        "env = AtariPreprocessing(env, screen_size=84, grayscale_newaxis=False, scale_obs=True)\n",
        "env = BufferWrapper(env, n_steps=4)"
      ],
      "metadata": {
        "id": "dlfkUN-DOoJq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(env.reset()[0][0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "OvNSR7VJgVfA",
        "outputId": "e19497d1-389a-47b8-95b1-ab80190bb2a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bab783a5d00>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "#First DQN\n",
        "___"
      ],
      "metadata": {
        "id": "5JOD1mUZoKFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "  def __init__ (self, input_shape,n_actions):\n",
        "    super(DQN,self).__init__()\n",
        "\n",
        "    self.conv=nn.Sequential(\n",
        "        nn.Conv2d(input_shape[0],32,kernel_size=8,stride=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32,64,kernel_size=4,stride=2),\n",
        "        nn.ReLU()   )\n",
        "\n",
        "    conv_out_size=self._get_conv_out(input_shape)\n",
        "    self.fc=nn.Sequential(\n",
        "        nn.Linear(conv_out_size,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,n_actions)\n",
        "    )\n",
        "\n",
        "\n",
        "  def _get_conv_out(self,shape):\n",
        "    zeros=self.conv(torch.zeros(1,*shape))\n",
        "    return int(np.prod(zeros.size()))\n",
        "\n",
        "\n",
        "  def forward(self,frames):\n",
        "    conv_output=self.conv(frames)\n",
        "    conv_output=conv_output.view(conv_output.size()[0],-1)\n",
        "    return self.fc(conv_output)"
      ],
      "metadata": {
        "id": "aVvs6wGSYRRT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqXh4ktkl_MV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "# ReplayBuffer\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "-MFSU1DAoBOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENV_NAME=\"ALE/SpaceInvaders-v5\"\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10000\n",
        "REPLAY_START_SIZE = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "EPSILON_DECAY_LAST_FRAME = 150000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.01\n",
        "DEFAULT_ENV_NAME = \"ALE/SpaceInvaders-v5\"\n",
        "MEAN_REWARD_BOUND = 500"
      ],
      "metadata": {
        "id": "V74_b8o-oFnC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import replace\n",
        "Experience= collections.namedtuple(\"Experience\",field_names=['state','action','reward','done','new_state'])\n",
        "\n",
        "class ExperienceBuffer():\n",
        "\n",
        "  def __init__(self,capacity):\n",
        "    self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def append(self,experience):\n",
        "    self.buffer.append(experience)\n",
        "\n",
        "  def sample(self,batch_size):\n",
        "    examples=np.random.choice(len(self.buffer), batch_size, replace=False)\n",
        "    list_of_exp=[self.buffer[ex] for ex in examples]\n",
        "    states, actions, rewards, dones, next_states= zip(*list_of_exp)\n",
        "    return np.array(states), np.array(actions), np.array(rewards,dtype=np.float32), np.array(dones,dtype=np.uint8), np.array(next_states)"
      ],
      "metadata": {
        "id": "s_IqnLCG4BMG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Agent\n",
        "___"
      ],
      "metadata": {
        "id": "OFS-cgWxe2fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self,env,exp_buffer):\n",
        "    self.env=env\n",
        "    self.exp_buffer=exp_buffer\n",
        "    self._reset()\n",
        "\n",
        "  def _reset(self):\n",
        "    self.state, _ = self.env.reset()\n",
        "    self.total_reward=0.0\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def play_step(self,net,epsilon=0.0,device='cpu'):\n",
        "    done_reward=None\n",
        "\n",
        "    if np.random.random()<epsilon:\n",
        "      action=self.env.action_space.sample()\n",
        "    else:\n",
        "      state_a=np.asarray([self.state])\n",
        "      state_v=torch.tensor(state_a).to(device)\n",
        "      q_vals_v=net(state_v)\n",
        "      _,act_v=torch.max(q_vals_v,dim=1)\n",
        "      action=int(act_v.item())\n",
        "    new_state,reward,terminated,truncated,info=self.env.step(action)\n",
        "    is_done = terminated or truncated\n",
        "    self.total_reward +=reward\n",
        "    exp=Experience(self.state,action,reward,is_done,new_state)\n",
        "    self.exp_buffer.append(exp)\n",
        "    self.state=new_state\n",
        "    if is_done:\n",
        "      done_reward=self.total_reward\n",
        "      self._reset()\n",
        "    return done_reward"
      ],
      "metadata": {
        "id": "OHIwalskBRKf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(batch,net,tgt_net,device='cpu'):\n",
        "  states,actions,rewards,dones,next_states=batch\n",
        "  states_v=torch.tensor(np.array(states,copy=False)).to(device)\n",
        "  next_statges_v=torch.tensor(np.array(next_states,copy=False)).to(device)\n",
        "  actions_v=torch.tensor(actions).to(device)\n",
        "  rewards_v=torch.tensor(rewards).to(device)\n",
        "  done_mask=torch.BoolTensor(dones).to(device)\n",
        "\n",
        "  state_action_values=net(states_v).gather(1,actions_v.unsqueeze(-1)).squeeze(-1)\n",
        "  next_state_values=tgt_net(next_statges_v).max(1)[0]\n",
        "  next_state_values[done_mask]==0.0\n",
        "\n",
        "  next_state_values=next_state_values.detach()\n",
        "  expected_state_action_values=next_state_values*GAMMA+rewards_v\n",
        "  return nn.MSELoss()(state_action_values,expected_state_action_values)\n"
      ],
      "metadata": {
        "id": "XMxBOVRHxWth"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "# The Training Part\n",
        "___"
      ],
      "metadata": {
        "id": "Y76E85OZBHou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--cuda\", default=False,\n",
        "                        action=\"store_true\", help=\"Enable cuda\")\n",
        "    parser.add_argument(\"--env\", default=DEFAULT_ENV_NAME,\n",
        "                        help=\"Name of the environment, default=\" +\n",
        "                             DEFAULT_ENV_NAME)\n",
        "    args = parser.parse_args(args=[])\n",
        "    device=torch.device('cuda'if args.cuda else 'cpu')\n",
        "    net=DQN(env.observation_space.shape,env.action_space.n).to(device)\n",
        "    tgt_net=DQN(env.observation_space.shape,env.action_space.n).to(device)\n",
        "    writer=SummaryWriter(comment='-'+ args.env)\n",
        "    print(net)\n",
        "\n",
        "    buffer=ExperienceBuffer(REPLAY_SIZE)\n",
        "    agent=Agent(env,buffer)\n",
        "    optimizer=torch.optim.Adam(net.parameters(),lr=LEARNING_RATE)\n",
        "\n",
        "    total_rewards=[]\n",
        "    frame_idx=0\n",
        "    epsilon=EPSILON_START\n",
        "    best_m_reward=None\n",
        "\n",
        "    model_path = args.env.replace('/', '_') + \"-best.dat\"\n",
        "    # Load saved model weights and training progress if they exist\n",
        "    if os.path.exists(model_path):\n",
        "        try:\n",
        "            checkpoint = torch.load(model_path, weights_only=False) # Changed this line\n",
        "            # Check if it's the new checkpoint format (a dictionary with 'net_state_dict')\n",
        "            if isinstance(checkpoint, dict) and 'net_state_dict' in checkpoint:\n",
        "                net.load_state_dict(checkpoint['net_state_dict'])\n",
        "                tgt_net.load_state_dict(checkpoint['net_state_dict'])\n",
        "                frame_idx = checkpoint['frame_idx']\n",
        "                best_m_reward = checkpoint['best_m_reward']\n",
        "                epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "                print(f\"Loaded model weights and progress from {model_path} (frame_idx: {frame_idx}, best_m_reward: {best_m_reward:.3f})\")\n",
        "            else: # Assume it's the old format where only state_dict was saved directly\n",
        "                net.load_state_dict(checkpoint)\n",
        "                tgt_net.load_state_dict(checkpoint)\n",
        "                print(f\"Loaded old format model weights from {model_path}. Training progress (frame_idx, best_m_reward, epsilon) will start from default.\")\n",
        "                # Reset frame_idx and best_m_reward as they are not available in old format\n",
        "                frame_idx = 0\n",
        "                best_m_reward = None\n",
        "                epsilon = EPSILON_START\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model from {model_path}: {e}. Starting training from scratch.\")\n",
        "            # Ensure these are reset if loading fails or for old format\n",
        "            frame_idx = 0\n",
        "            best_m_reward = None\n",
        "            epsilon = EPSILON_START\n",
        "\n",
        "    # Load episode rewards history if the file exists\n",
        "    episode_rewards_file_path = 'episode_rewards.txt'\n",
        "    if os.path.exists(episode_rewards_file_path):\n",
        "        with open(episode_rewards_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    total_rewards.append(float(line.strip()))\n",
        "                except ValueError:\n",
        "                    continue # Skip invalid lines\n",
        "        print(f\"Loaded {len(total_rewards)} historical rewards from {episode_rewards_file_path}\")\n",
        "\n",
        "    ts_frame=0\n",
        "    ts=time.time()\n",
        "\n",
        "    # Open the file for appending new individual episode rewards\n",
        "    episode_rewards_file = open(episode_rewards_file_path, 'a')\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            frame_idx+=1\n",
        "            epsilon=max(EPSILON_FINAL,EPSILON_START-frame_idx/EPSILON_DECAY_LAST_FRAME)\n",
        "            reward=agent.play_step(net,epsilon,device=device)\n",
        "            if reward is not None:\n",
        "                total_rewards.append(reward)\n",
        "                # Save the individual episode reward to file\n",
        "                episode_rewards_file.write(f\"{reward}\\n\")\n",
        "                episode_rewards_file.flush() # Ensure it's written to disk immediately\n",
        "\n",
        "                speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "                ts_frame = frame_idx\n",
        "                ts = time.time()\n",
        "                m_reward = np.mean(total_rewards[-100:])\n",
        "                print(\"%d: done %d games, reward %.3f, \"\"eps %.2f, speed %.2f f/s\" % (frame_idx, len(total_rewards), m_reward, epsilon,speed))\n",
        "                writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "                writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "                writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "                writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "                if best_m_reward is None or best_m_reward < m_reward:\n",
        "                    checkpoint = {\n",
        "                        'net_state_dict': net.state_dict(),\n",
        "                        'frame_idx': frame_idx,\n",
        "                        'best_m_reward': m_reward,\n",
        "                    }\n",
        "                    torch.save(checkpoint, model_path)\n",
        "                    if best_m_reward is not None:\n",
        "                        print(\"Best reward updated %.3f -> %.3f\" % (best_m_reward, m_reward))\n",
        "                    best_m_reward = m_reward\n",
        "                if m_reward > MEAN_REWARD_BOUND:\n",
        "                    print(\"Solved in %d frames!\" % frame_idx)\n",
        "                    break\n",
        "            if len(buffer) < REPLAY_START_SIZE:\n",
        "                continue\n",
        "\n",
        "            if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "                tgt_net.load_state_dict(net.state_dict())\n",
        "            optimizer.zero_grad()\n",
        "            batch=buffer.sample(BATCH_SIZE)\n",
        "            loss_t=calc_loss(batch,net,tgt_net,device=device)\n",
        "            loss_t.backward()\n",
        "            optimizer.step()\n",
        "    finally:\n",
        "        # Ensure the file is closed even if an error occurs or training stops\n",
        "        episode_rewards_file.close()"
      ],
      "metadata": {
        "id": "swEeODE0BK8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b250df03-da86-430a-8a0c-5e0ad5ff1822"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=5184, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n",
            "Loaded model weights and progress from ALE_SpaceInvaders-v5-best.dat (frame_idx: 1144, best_m_reward: 182.550)\n",
            "Loaded 250 historical rewards from episode_rewards.txt\n",
            "1668: done 251 games, reward 167.400, eps 0.99, speed 2945.11 f/s\n",
            "2283: done 252 games, reward 168.000, eps 0.98, speed 597.09 f/s\n",
            "3046: done 253 games, reward 169.150, eps 0.98, speed 860.28 f/s\n",
            "3414: done 254 games, reward 168.900, eps 0.98, speed 873.56 f/s\n",
            "4179: done 255 games, reward 169.700, eps 0.97, speed 928.44 f/s\n",
            "4471: done 256 games, reward 169.650, eps 0.97, speed 833.57 f/s\n",
            "4771: done 257 games, reward 169.050, eps 0.97, speed 885.68 f/s\n",
            "5489: done 258 games, reward 170.150, eps 0.96, speed 892.97 f/s\n",
            "5932: done 259 games, reward 170.550, eps 0.96, speed 901.02 f/s\n",
            "6502: done 260 games, reward 168.800, eps 0.96, speed 877.74 f/s\n",
            "6977: done 261 games, reward 169.050, eps 0.95, speed 762.80 f/s\n",
            "7625: done 262 games, reward 168.700, eps 0.95, speed 572.51 f/s\n",
            "7916: done 263 games, reward 167.250, eps 0.95, speed 541.95 f/s\n",
            "8319: done 264 games, reward 163.150, eps 0.94, speed 673.70 f/s\n",
            "8689: done 265 games, reward 163.100, eps 0.94, speed 879.98 f/s\n",
            "9154: done 266 games, reward 162.050, eps 0.94, speed 856.89 f/s\n",
            "9519: done 267 games, reward 158.500, eps 0.94, speed 877.59 f/s\n",
            "9895: done 268 games, reward 158.650, eps 0.93, speed 824.13 f/s\n",
            "10446: done 269 games, reward 157.700, eps 0.93, speed 884.80 f/s\n",
            "10852: done 270 games, reward 157.650, eps 0.93, speed 833.01 f/s\n",
            "11620: done 271 games, reward 154.850, eps 0.92, speed 22.42 f/s\n",
            "12014: done 272 games, reward 154.100, eps 0.92, speed 12.39 f/s\n",
            "12588: done 273 games, reward 153.200, eps 0.92, speed 11.02 f/s\n",
            "13074: done 274 games, reward 154.450, eps 0.91, speed 11.30 f/s\n",
            "13484: done 275 games, reward 154.600, eps 0.91, speed 11.22 f/s\n",
            "13804: done 276 games, reward 153.000, eps 0.91, speed 11.17 f/s\n",
            "14415: done 277 games, reward 153.350, eps 0.90, speed 11.18 f/s\n",
            "14831: done 278 games, reward 149.350, eps 0.90, speed 11.21 f/s\n",
            "15695: done 279 games, reward 150.850, eps 0.90, speed 11.21 f/s\n",
            "16227: done 280 games, reward 151.200, eps 0.89, speed 11.28 f/s\n",
            "16754: done 281 games, reward 150.900, eps 0.89, speed 11.35 f/s\n",
            "17273: done 282 games, reward 151.100, eps 0.88, speed 11.19 f/s\n",
            "17793: done 283 games, reward 152.200, eps 0.88, speed 11.17 f/s\n",
            "18103: done 284 games, reward 152.200, eps 0.88, speed 11.39 f/s\n",
            "18674: done 285 games, reward 150.650, eps 0.88, speed 11.45 f/s\n",
            "18972: done 286 games, reward 150.500, eps 0.87, speed 11.32 f/s\n",
            "19745: done 287 games, reward 151.150, eps 0.87, speed 11.36 f/s\n",
            "20059: done 288 games, reward 151.750, eps 0.87, speed 11.50 f/s\n",
            "20498: done 289 games, reward 150.050, eps 0.86, speed 11.40 f/s\n",
            "21034: done 290 games, reward 150.800, eps 0.86, speed 11.48 f/s\n",
            "21764: done 291 games, reward 149.800, eps 0.85, speed 11.52 f/s\n",
            "22100: done 292 games, reward 145.900, eps 0.85, speed 11.42 f/s\n",
            "22596: done 293 games, reward 147.500, eps 0.85, speed 11.61 f/s\n",
            "22968: done 294 games, reward 147.850, eps 0.85, speed 11.55 f/s\n",
            "23854: done 295 games, reward 151.350, eps 0.84, speed 11.63 f/s\n",
            "24588: done 296 games, reward 152.350, eps 0.84, speed 11.55 f/s\n",
            "25111: done 297 games, reward 152.150, eps 0.83, speed 11.72 f/s\n",
            "25610: done 298 games, reward 149.600, eps 0.83, speed 11.32 f/s\n",
            "26249: done 299 games, reward 149.900, eps 0.83, speed 11.48 f/s\n",
            "26693: done 300 games, reward 147.600, eps 0.82, speed 11.55 f/s\n",
            "27157: done 301 games, reward 147.400, eps 0.82, speed 11.62 f/s\n",
            "27683: done 302 games, reward 147.900, eps 0.82, speed 11.54 f/s\n",
            "28171: done 303 games, reward 148.700, eps 0.81, speed 11.49 f/s\n",
            "28629: done 304 games, reward 149.300, eps 0.81, speed 11.48 f/s\n",
            "29028: done 305 games, reward 149.650, eps 0.81, speed 11.50 f/s\n",
            "29328: done 306 games, reward 149.350, eps 0.80, speed 11.59 f/s\n",
            "30182: done 307 games, reward 151.300, eps 0.80, speed 11.50 f/s\n",
            "30710: done 308 games, reward 151.500, eps 0.80, speed 11.46 f/s\n",
            "31173: done 309 games, reward 151.000, eps 0.79, speed 11.40 f/s\n",
            "32147: done 310 games, reward 153.400, eps 0.79, speed 11.49 f/s\n",
            "32627: done 311 games, reward 153.150, eps 0.78, speed 11.38 f/s\n",
            "33407: done 312 games, reward 154.500, eps 0.78, speed 11.60 f/s\n",
            "34106: done 313 games, reward 157.900, eps 0.77, speed 11.56 f/s\n",
            "34928: done 314 games, reward 159.000, eps 0.77, speed 11.55 f/s\n",
            "35348: done 315 games, reward 157.700, eps 0.76, speed 11.65 f/s\n",
            "35822: done 316 games, reward 156.950, eps 0.76, speed 11.61 f/s\n",
            "36086: done 317 games, reward 157.250, eps 0.76, speed 11.54 f/s\n",
            "36359: done 318 games, reward 156.450, eps 0.76, speed 11.49 f/s\n",
            "36638: done 319 games, reward 155.900, eps 0.76, speed 11.63 f/s\n",
            "37434: done 320 games, reward 156.250, eps 0.75, speed 11.53 f/s\n",
            "37965: done 321 games, reward 156.750, eps 0.75, speed 11.46 f/s\n",
            "38343: done 322 games, reward 156.650, eps 0.74, speed 11.41 f/s\n",
            "39180: done 323 games, reward 157.750, eps 0.74, speed 11.39 f/s\n",
            "39835: done 324 games, reward 159.300, eps 0.73, speed 11.44 f/s\n",
            "40216: done 325 games, reward 158.800, eps 0.73, speed 11.41 f/s\n",
            "40611: done 326 games, reward 156.900, eps 0.73, speed 11.42 f/s\n",
            "40887: done 327 games, reward 152.150, eps 0.73, speed 10.87 f/s\n",
            "41606: done 328 games, reward 151.850, eps 0.72, speed 11.25 f/s\n",
            "42034: done 329 games, reward 149.000, eps 0.72, speed 11.25 f/s\n",
            "42332: done 330 games, reward 147.800, eps 0.72, speed 11.42 f/s\n",
            "43100: done 331 games, reward 148.250, eps 0.71, speed 11.38 f/s\n",
            "43537: done 332 games, reward 148.750, eps 0.71, speed 11.00 f/s\n",
            "44032: done 333 games, reward 147.400, eps 0.71, speed 11.16 f/s\n",
            "44576: done 334 games, reward 147.450, eps 0.70, speed 11.11 f/s\n",
            "44987: done 335 games, reward 146.100, eps 0.70, speed 11.19 f/s\n",
            "45459: done 336 games, reward 145.800, eps 0.70, speed 11.10 f/s\n",
            "45765: done 337 games, reward 144.350, eps 0.69, speed 11.19 f/s\n",
            "46125: done 338 games, reward 143.800, eps 0.69, speed 11.05 f/s\n",
            "46678: done 339 games, reward 143.500, eps 0.69, speed 11.03 f/s\n",
            "47050: done 340 games, reward 143.100, eps 0.69, speed 11.01 f/s\n",
            "47560: done 341 games, reward 143.100, eps 0.68, speed 10.95 f/s\n",
            "47915: done 342 games, reward 141.300, eps 0.68, speed 10.89 f/s\n",
            "48200: done 343 games, reward 141.100, eps 0.68, speed 10.67 f/s\n",
            "48450: done 344 games, reward 139.100, eps 0.68, speed 10.77 f/s\n",
            "49147: done 345 games, reward 141.800, eps 0.67, speed 10.79 f/s\n",
            "49433: done 346 games, reward 141.350, eps 0.67, speed 10.82 f/s\n",
            "49817: done 347 games, reward 141.100, eps 0.67, speed 10.80 f/s\n",
            "50047: done 348 games, reward 140.200, eps 0.67, speed 10.60 f/s\n",
            "50347: done 349 games, reward 139.850, eps 0.66, speed 10.54 f/s\n",
            "50722: done 350 games, reward 139.500, eps 0.66, speed 10.05 f/s\n",
            "51044: done 351 games, reward 139.550, eps 0.66, speed 10.08 f/s\n",
            "51434: done 352 games, reward 138.600, eps 0.66, speed 10.30 f/s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1090191416.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mloss_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2972833507.py\u001b[0m in \u001b[0;36mcalc_loss\u001b[0;34m(batch, net, tgt_net, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdone_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mstate_action_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mnext_state_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_statges_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mnext_state_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdone_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1247924437.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mconv_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mconv_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IanyBjwpN5QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_tBwnbbOaDb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}